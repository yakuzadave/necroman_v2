{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-gradient llama-index --upgrade\n",
    "%pip install llama-index-finetuning --upgrade\n",
    "%pip install langchain-community --upgrade\n",
    "%pip install langchain --upgrade\n",
    "%pip install langchain-experimental --upgrade\n",
    "%pip install llama-index-embeddings-gradient --upgrade\n",
    "%pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "gradient_api_key = os.getenv(\"GRADIENT_API_KEY\")\n",
    "gradient_workspace = os.getenv(\"GRADIENT_WORKSPACE_ID\")\n",
    "from llama_index.llms.gradient import GradientBaseModelLLM\n",
    "from llama_index.finetuning import GradientFinetuneEngine\n",
    "os.environ[\"GRADIENT_API_KEY\"] = gradient_api_key\n",
    "os.environ[\"GRADIENT_WORKSPACE_ID\"] = gradient_workspace\n",
    "\n",
    "\n",
    "from llama_index.core.response_synthesizers import Refine\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.core.data_structs import Node\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core.postprocessor import TimeWeightedPostprocessor\n",
    "\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "# from llama_index.core.vector_stores\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "\n",
    "from llama_index.embeddings.gradient import GradientEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-cli\n",
      "  Downloading langchain_cli-0.0.24-py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.40 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-cli) (3.1.43)\n",
      "Collecting langserve>=0.0.51 (from langserve[all]>=0.0.51->langchain-cli)\n",
      "  Downloading langserve-0.2.2-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting libcst<2.0.0,>=1.3.1 (from langchain-cli)\n",
      "  Downloading libcst-1.4.0-cp312-cp312-win_amd64.whl.metadata (17 kB)\n",
      "Collecting tomlkit<0.13.0,>=0.12.2 (from langchain-cli)\n",
      "  Downloading tomlkit-0.12.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<0.10.0,>=0.9.0 (from typer[all]<0.10.0,>=0.9.0->langchain-cli)\n",
      "  Using cached typer-0.9.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting uvicorn<0.24.0,>=0.23.2 (from langchain-cli)\n",
      "  Downloading uvicorn-0.23.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython<4.0.0,>=3.1.40->langchain-cli) (4.0.11)\n",
      "Requirement already satisfied: httpx>=0.23.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (0.27.0)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (0.2.5)\n",
      "Requirement already satisfied: orjson>=2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (3.10.4)\n",
      "Requirement already satisfied: pydantic>=1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (1.10.15)\n",
      "Collecting pyproject-toml<0.0.11,>=0.0.10 (from langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli)\n",
      "  Downloading pyproject_toml-0.0.10-py3-none-any.whl.metadata (642 bytes)\n",
      "Requirement already satisfied: fastapi<1,>=0.90.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langserve[all]>=0.0.51->langchain-cli) (0.110.1)\n",
      "Collecting sse-starlette<2.0.0,>=1.3.0 (from langserve[all]>=0.0.51->langchain-cli)\n",
      "  Downloading sse_starlette-1.8.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: pyyaml>=5.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from libcst<2.0.0,>=1.3.1->langchain-cli) (6.0.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<0.10.0,>=0.9.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (8.1.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer<0.10.0,>=0.9.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (4.10.0)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typer[all]<0.10.0,>=0.9.0->langchain-cli) (13.7.1)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from uvicorn<0.24.0,>=0.23.2->langchain-cli) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fastapi<1,>=0.90.1->langserve[all]>=0.0.51->langchain-cli) (0.37.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.40->langchain-cli) (5.0.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (4.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (1.0.5)\n",
      "Requirement already satisfied: idna in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (3.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx>=0.23.0->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (1.3.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (0.1.75)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (23.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.3,>=0.1->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (8.2.3)\n",
      "Collecting setuptools>=42 (from pyproject-toml<0.0.11,>=0.0.10->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli)\n",
      "  Using cached setuptools-70.0.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting wheel (from pyproject-toml<0.0.11,>=0.0.10->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli)\n",
      "  Using cached wheel-0.43.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting toml (from pyproject-toml<0.0.11,>=0.0.10->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jsonschema (from pyproject-toml<0.0.11,>=0.0.10->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli)\n",
      "  Using cached jsonschema-4.22.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dcarm\\appdata\\roaming\\python\\python312\\site-packages (from rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (2.17.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (3.0.0)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.1->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (2.31.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<0.10.0,>=0.9.0->langchain-cli) (0.1.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema->pyproject-toml<0.0.11,>=0.0.10->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (23.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema->pyproject-toml<0.0.11,>=0.0.10->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli)\n",
      "  Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema->pyproject-toml<0.0.11,>=0.0.10->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema->pyproject-toml<0.0.11,>=0.0.10->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli)\n",
      "  Downloading rpds_py-0.18.1-cp312-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.1->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.1->langserve>=0.0.51->langserve[all]>=0.0.51->langchain-cli) (2.2.1)\n",
      "Downloading langchain_cli-0.0.24-py3-none-any.whl (88 kB)\n",
      "   ---------------------------------------- 0.0/88.2 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 81.9/88.2 kB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 88.2/88.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading langserve-0.2.2-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.1/1.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.3/1.2 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.4/1.2 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.6/1.2 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.8/1.2 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.9/1.2 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.1/1.2 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 3.4 MB/s eta 0:00:00\n",
      "Downloading libcst-1.4.0-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/2.0 MB 3.2 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.3/2.0 MB 3.5 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.5/2.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.6/2.0 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.0 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/2.0 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.0 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.4/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.5/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.7/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/2.0 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.0/2.0 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading tomlkit-0.12.5-py3-none-any.whl (37 kB)\n",
      "Using cached typer-0.9.4-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.5/59.5 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading pyproject_toml-0.0.10-py3-none-any.whl (6.9 kB)\n",
      "Downloading sse_starlette-1.8.2-py3-none-any.whl (8.9 kB)\n",
      "Using cached setuptools-70.0.0-py3-none-any.whl (863 kB)\n",
      "Using cached jsonschema-4.22.0-py3-none-any.whl (88 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
      "Using cached jsonschema_specifications-2023.12.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.18.1-cp312-none-win_amd64.whl (209 kB)\n",
      "   ---------------------------------------- 0.0/209.3 kB ? eta -:--:--\n",
      "   ----------------- ---------------------- 92.2/209.3 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 209.3/209.3 kB 3.2 MB/s eta 0:00:00\n",
      "Installing collected packages: wheel, tomlkit, toml, setuptools, rpds-py, libcst, uvicorn, typer, referencing, jsonschema-specifications, sse-starlette, jsonschema, pyproject-toml, langserve, langchain-cli\n",
      "  Attempting uninstall: uvicorn\n",
      "    Found existing installation: uvicorn 0.29.0\n",
      "    Uninstalling uvicorn-0.29.0:\n",
      "      Successfully uninstalled uvicorn-0.29.0\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.12.3\n",
      "    Uninstalling typer-0.12.3:\n",
      "      Successfully uninstalled typer-0.12.3\n",
      "Successfully installed jsonschema-4.22.0 jsonschema-specifications-2023.12.1 langchain-cli-0.0.24 langserve-0.2.2 libcst-1.4.0 pyproject-toml-0.0.10 referencing-0.35.1 rpds-py-0.18.1 setuptools-70.0.0 sse-starlette-1.8.2 toml-0.10.2 tomlkit-0.12.5 typer-0.9.4 uvicorn-0.23.2 wheel-0.43.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone-client\n",
      "  Downloading pinecone_client-4.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (2024.2.2)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone-client)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (4.10.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pinecone-client) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
      "Downloading pinecone_client-4.1.1-py3-none-any.whl (216 kB)\n",
      "   ---------------------------------------- 0.0/216.2 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/216.2 kB 640.0 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 153.6/216.2 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 216.2/216.2 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, pinecone-client\n",
      "Successfully installed pinecone-client-4.1.1 pinecone-plugin-interface-0.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-firestore\n",
      "  Downloading langchain_google_firestore-0.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting langchain-google-vertexai\n",
      "  Downloading langchain_google_vertexai-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-google-firestore) (0.2.5)\n",
      "Requirement already satisfied: langchain-community<1.0.0,>=0.0.18 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-google-firestore) (0.2.4)\n",
      "Collecting google-cloud-firestore<3.0.0,>=2.16.0 (from langchain-google-firestore)\n",
      "  Downloading google_cloud_firestore-2.16.0-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting more-itertools<11.0.0,>=10.2.0 (from langchain-google-firestore)\n",
      "  Downloading more_itertools-10.3.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.47.0 (from langchain-google-vertexai)\n",
      "  Downloading google_cloud_aiplatform-1.54.1-py2.py3-none-any.whl.metadata (30 kB)\n",
      "Collecting google-cloud-storage<3.0.0,>=2.14.0 (from langchain-google-vertexai)\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Using cached google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-auth<3.0.0dev,>=2.14.1 (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Downloading google_auth-2.30.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0 (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Using cached proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (23.2)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Downloading google_cloud_bigquery-3.24.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Downloading shapely-2.0.4-cp312-cp312-win_amd64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.10.15)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-cloud-core<3.0.0dev,>=1.4.1 (from google-cloud-firestore<3.0.0,>=2.16.0->langchain-google-firestore)\n",
      "  Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.6.0 (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai)\n",
      "  Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.31.0)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai)\n",
      "  Downloading google-crc32c-1.5.0.tar.gz (12 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (0.6.4)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (0.2.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (0.1.75)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (1.26.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.1.1->langchain-google-firestore) (1.33)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (0.9.0)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Downloading grpcio-1.64.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in c:\\users\\dcarm\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.9.0.post0)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.1.1->langchain-google-firestore) (3.0.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain<0.3.0,>=0.2.0->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (0.2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (3.10.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (3.0.3)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dcarm\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<1.0.0,>=0.0.18->langchain-google-firestore) (1.0.0)\n",
      "Downloading langchain_google_firestore-0.3.0-py3-none-any.whl (22 kB)\n",
      "Downloading langchain_google_vertexai-1.0.5-py3-none-any.whl (63 kB)\n",
      "   ---------------------------------------- 0.0/63.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 63.8/63.8 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading google_cloud_aiplatform-1.54.1-py2.py3-none-any.whl (5.1 MB)\n",
      "   ---------------------------------------- 0.0/5.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/5.1 MB 3.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.3/5.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.5/5.1 MB 4.1 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.7/5.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.9/5.1 MB 4.2 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.1/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.3/5.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 1.5/5.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 1.7/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.9/5.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.1/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 2.3/5.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.5/5.1 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.6/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.9/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.0/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.3/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 3.5/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.6/5.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.9/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.1/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.2/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.5/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 4.7/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 4.9/5.1 MB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.1/5.1 MB 4.3 MB/s eta 0:00:00\n",
      "Downloading google_cloud_firestore-2.16.0-py2.py3-none-any.whl (317 kB)\n",
      "   ---------------------------------------- 0.0/317.4 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 174.1/317.4 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 317.4/317.4 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 122.9/126.5 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 126.5/126.5 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading more_itertools-10.3.0-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.2/59.2 kB 3.1 MB/s eta 0:00:00\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "Downloading google_auth-2.30.0-py2.py3-none-any.whl (193 kB)\n",
      "   ---------------------------------------- 0.0/193.7 kB ? eta -:--:--\n",
      "   -------------------------------------- - 184.3/193.7 kB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 193.7/193.7 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading google_cloud_bigquery-3.24.0-py2.py3-none-any.whl (238 kB)\n",
      "   ---------------------------------------- 0.0/238.5 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 163.8/238.5 kB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 238.5/238.5 kB 3.6 MB/s eta 0:00:00\n",
      "Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_cloud_resource_manager-1.12.3-py2.py3-none-any.whl (333 kB)\n",
      "   ---------------------------------------- 0.0/333.7 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 194.6/333.7 kB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 333.7/333.7 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading google_resumable_media-2.7.1-py2.py3-none-any.whl (81 kB)\n",
      "   ---------------------------------------- 0.0/81.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 81.2/81.2 kB 2.3 MB/s eta 0:00:00\n",
      "Using cached proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "Using cached protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading shapely-2.0.4-cp312-cp312-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.4/1.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 0.6/1.4 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.1/1.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.3/1.4 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.4/1.4 MB 4.8 MB/s eta 0:00:00\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
      "   ---------------------------------------- 0.0/229.2 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 163.8/229.2 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 229.2/229.2 kB 3.5 MB/s eta 0:00:00\n",
      "Downloading grpc_google_iam_v1-0.13.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading grpcio-1.64.1-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/4.1 MB 10.9 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.4/4.1 MB 6.3 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.5/4.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.5/4.1 MB 6.0 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 1.0/4.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.2/4.1 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.5/4.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.7/4.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.0/4.1 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.2/4.1 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.4/4.1 MB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.7/4.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.9/4.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.1/4.1 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.4/4.1 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.6/4.1 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.9/4.1 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.1/4.1 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.1/4.1 MB 5.0 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.62.2-py3-none-any.whl (14 kB)\n",
      "Using cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Building wheels for collected packages: google-crc32c\n",
      "  Building wheel for google-crc32c (pyproject.toml): started\n",
      "  Building wheel for google-crc32c (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for google-crc32c: filename=google_crc32c-1.5.0-py3-none-any.whl size=13046 sha256=ba5c534aee3714530ce8aab9b531ee72a022cb8251e704b6fdd617500bfba14d\n",
      "  Stored in directory: c:\\users\\dcarm\\appdata\\local\\pip\\cache\\wheels\\40\\b9\\2e\\089df51c5e6f7cda282c650457a1d9a7a55bf6386d8de8bf3d\n",
      "Successfully built google-crc32c\n",
      "Installing collected packages: shapely, pyasn1, protobuf, more-itertools, grpcio, google-crc32c, docstring-parser, cachetools, rsa, pyasn1-modules, proto-plus, googleapis-common-protos, google-resumable-media, grpcio-status, google-auth, grpc-google-iam-v1, google-api-core, google-cloud-core, google-cloud-storage, google-cloud-resource-manager, google-cloud-firestore, google-cloud-bigquery, langchain-google-firestore, google-cloud-aiplatform, langchain-google-vertexai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.26.1\n",
      "    Uninstalling protobuf-5.26.1:\n",
      "      Successfully uninstalled protobuf-5.26.1\n",
      "Successfully installed cachetools-5.3.3 docstring-parser-0.16 google-api-core-2.19.0 google-auth-2.30.0 google-cloud-aiplatform-1.54.1 google-cloud-bigquery-3.24.0 google-cloud-core-2.4.1 google-cloud-firestore-2.16.0 google-cloud-resource-manager-1.12.3 google-cloud-storage-2.17.0 google-crc32c-1.5.0 google-resumable-media-2.7.1 googleapis-common-protos-1.63.1 grpc-google-iam-v1-0.13.0 grpcio-1.64.1 grpcio-status-1.62.2 langchain-google-firestore-0.3.0 langchain-google-vertexai-1.0.5 more-itertools-10.3.0 proto-plus-1.23.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 rsa-4.9 shapely-2.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade langchain-google-firestore langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': [-0.8417011499404907,\n",
       "  -0.38018935918807983,\n",
       "  -2.2074687480926514,\n",
       "  0.4917255938053131,\n",
       "  0.3621918261051178,\n",
       "  0.2340126782655716,\n",
       "  -0.45399677753448486,\n",
       "  1.6895288228988647,\n",
       "  1.041884183883667,\n",
       "  1.5690504312515259,\n",
       "  -0.9136074185371399,\n",
       "  0.8415181040763855,\n",
       "  -0.76592618227005,\n",
       "  -0.14406271278858185,\n",
       "  -0.6489260196685791,\n",
       "  0.3822888135910034,\n",
       "  0.9709786772727966,\n",
       "  -2.15132999420166,\n",
       "  0.567293107509613,\n",
       "  0.15537816286087036,\n",
       "  -0.14207956194877625,\n",
       "  -0.7902367115020752,\n",
       "  0.522583544254303,\n",
       "  -0.5737978219985962,\n",
       "  0.89002925157547,\n",
       "  -1.1292469501495361,\n",
       "  0.5042896866798401,\n",
       "  -0.34414201974868774,\n",
       "  0.7126677632331848,\n",
       "  -0.4482181668281555,\n",
       "  0.5081705451011658,\n",
       "  0.5893732309341431,\n",
       "  0.750646710395813,\n",
       "  -1.4699534177780151,\n",
       "  -0.5100438594818115,\n",
       "  -0.9757871031761169,\n",
       "  -0.8095923066139221,\n",
       "  0.3274163603782654,\n",
       "  -0.44592535495758057,\n",
       "  -0.6402671933174133,\n",
       "  -0.2991487383842468,\n",
       "  0.8135250806808472,\n",
       "  0.3214851915836334,\n",
       "  -1.742933750152588,\n",
       "  0.04424731060862541,\n",
       "  0.1767583191394806,\n",
       "  0.8593596816062927,\n",
       "  1.17354154586792,\n",
       "  -0.1259915679693222,\n",
       "  -1.0856235027313232,\n",
       "  -0.6992676854133606,\n",
       "  -0.8484439253807068,\n",
       "  -0.10795703530311584,\n",
       "  -0.44565799832344055,\n",
       "  -0.3380918502807617,\n",
       "  0.2886258065700531,\n",
       "  1.2102024555206299,\n",
       "  1.224359154701233,\n",
       "  -0.824627697467804,\n",
       "  -0.1998443752527237,\n",
       "  2.3671953678131104,\n",
       "  0.8806930780410767,\n",
       "  -0.9435195922851562,\n",
       "  2.0540881156921387,\n",
       "  -0.4508725702762604,\n",
       "  -1.1721258163452148,\n",
       "  -0.38937634229660034,\n",
       "  0.7752256989479065,\n",
       "  -0.05295642465353012,\n",
       "  -0.5238955020904541,\n",
       "  -0.1129118800163269,\n",
       "  0.6754636764526367,\n",
       "  0.5380185842514038,\n",
       "  -0.34276601672172546,\n",
       "  0.08831766247749329,\n",
       "  1.0124480724334717,\n",
       "  -0.5789387822151184,\n",
       "  0.006821304559707642,\n",
       "  0.22172623872756958,\n",
       "  1.1436903476715088,\n",
       "  0.5863435864448547,\n",
       "  -0.33330482244491577,\n",
       "  2.5780813694000244,\n",
       "  0.7732089757919312,\n",
       "  0.8912984132766724,\n",
       "  -0.5224187970161438,\n",
       "  0.0424639955163002,\n",
       "  0.3073224127292633,\n",
       "  -0.17493286728858948,\n",
       "  0.5302537679672241,\n",
       "  0.021006222814321518,\n",
       "  1.3858431577682495,\n",
       "  -0.27497556805610657,\n",
       "  1.1916522979736328,\n",
       "  -0.6879911422729492,\n",
       "  -0.21014992892742157,\n",
       "  -1.526775598526001,\n",
       "  0.15189771354198456,\n",
       "  -0.29650941491127014,\n",
       "  -0.07747131586074829,\n",
       "  -0.8107516765594482,\n",
       "  -0.7743836045265198,\n",
       "  -1.5608493089675903,\n",
       "  -0.6104221940040588,\n",
       "  -0.3456820249557495,\n",
       "  1.2356356382369995,\n",
       "  0.6588526964187622,\n",
       "  -0.23730775713920593,\n",
       "  0.5604588389396667,\n",
       "  -1.1923112869262695,\n",
       "  -0.8408346772193909,\n",
       "  -0.030404865741729736,\n",
       "  -0.9483523964881897,\n",
       "  -1.4978764057159424,\n",
       "  -1.5958017110824585,\n",
       "  0.5474492907524109,\n",
       "  0.6175005435943604,\n",
       "  0.6433731317520142,\n",
       "  0.5800462961196899,\n",
       "  1.198291301727295,\n",
       "  -0.9166950583457947,\n",
       "  0.11138026416301727,\n",
       "  -0.35723087191581726,\n",
       "  1.5890650749206543,\n",
       "  0.3125762343406677,\n",
       "  1.2854526042938232,\n",
       "  -0.6645044088363647,\n",
       "  0.3247619867324829,\n",
       "  0.614185631275177,\n",
       "  0.1111680343747139,\n",
       "  0.6480899453163147,\n",
       "  -0.25158190727233887,\n",
       "  0.6511196494102478,\n",
       "  -0.09877043217420578,\n",
       "  -0.18361756205558777,\n",
       "  0.4858951270580292,\n",
       "  0.2187148928642273,\n",
       "  -0.0035452768206596375,\n",
       "  -1.0174273252487183,\n",
       "  0.3906150460243225,\n",
       "  -0.5568593740463257,\n",
       "  0.5275993943214417,\n",
       "  1.4046862125396729,\n",
       "  0.4882352650165558,\n",
       "  0.021662190556526184,\n",
       "  0.03965705633163452,\n",
       "  0.41374170780181885,\n",
       "  0.7865815758705139,\n",
       "  -0.4841468930244446,\n",
       "  1.2961677312850952,\n",
       "  -0.2931900918483734,\n",
       "  0.9517207145690918,\n",
       "  0.5657065510749817,\n",
       "  0.1358768492937088,\n",
       "  1.3818891048431396,\n",
       "  -0.9013179540634155,\n",
       "  0.5767999887466431,\n",
       "  -0.24297045171260834,\n",
       "  0.19873686134815216,\n",
       "  -0.3815580904483795,\n",
       "  1.9992188215255737,\n",
       "  -0.7873321175575256,\n",
       "  -0.6525169610977173,\n",
       "  0.5406394600868225,\n",
       "  0.21760888397693634,\n",
       "  -1.3228702545166016,\n",
       "  0.15935133397579193,\n",
       "  1.308152198791504,\n",
       "  -0.02416020818054676,\n",
       "  1.045106053352356,\n",
       "  0.48852816224098206,\n",
       "  -1.5464973449707031,\n",
       "  -0.22345617413520813,\n",
       "  0.1449947953224182,\n",
       "  0.6780936121940613,\n",
       "  -0.6152915954589844,\n",
       "  0.8675615787506104,\n",
       "  -0.7852086424827576,\n",
       "  -0.713814914226532,\n",
       "  -0.27035632729530334,\n",
       "  0.9752989411354065,\n",
       "  -0.24173782765865326,\n",
       "  0.10679765045642853,\n",
       "  0.13379301130771637,\n",
       "  -0.7352513074874878,\n",
       "  0.3454363942146301,\n",
       "  -0.10232943296432495,\n",
       "  0.09908469021320343,\n",
       "  0.8045200109481812,\n",
       "  0.51617032289505,\n",
       "  -0.19646157324314117,\n",
       "  -0.10655508935451508,\n",
       "  0.13849309086799622,\n",
       "  0.29823410511016846,\n",
       "  0.29219546914100647,\n",
       "  0.2607807219028473,\n",
       "  1.6095678806304932,\n",
       "  -0.42859405279159546,\n",
       "  0.5673663020133972,\n",
       "  -0.03147424757480621,\n",
       "  -0.1730995774269104,\n",
       "  0.7566755414009094,\n",
       "  -0.30775564908981323,\n",
       "  1.2066876888275146,\n",
       "  -0.8259457349777222,\n",
       "  0.6628606915473938,\n",
       "  0.1077190563082695,\n",
       "  -0.25825831294059753,\n",
       "  -0.3929887115955353,\n",
       "  -0.5770624279975891,\n",
       "  0.632230818271637,\n",
       "  0.08466559648513794,\n",
       "  0.8077861070632935,\n",
       "  -0.16202402114868164,\n",
       "  0.4539174735546112,\n",
       "  -0.6852940320968628,\n",
       "  -0.0851171538233757,\n",
       "  -0.12123504281044006,\n",
       "  -1.1651939153671265,\n",
       "  0.25917741656303406,\n",
       "  0.837771475315094,\n",
       "  0.8349462151527405,\n",
       "  0.05591896176338196,\n",
       "  1.0194776058197021,\n",
       "  -0.4152367115020752,\n",
       "  0.0014382638037204742,\n",
       "  -1.8913350105285645,\n",
       "  -0.16461984813213348,\n",
       "  -0.2559341788291931,\n",
       "  1.0541858673095703,\n",
       "  0.887588381767273,\n",
       "  -0.9128385782241821,\n",
       "  1.294312834739685,\n",
       "  0.9265315532684326,\n",
       "  1.3040516376495361,\n",
       "  0.5376616716384888,\n",
       "  0.732145369052887,\n",
       "  0.6844672560691833,\n",
       "  0.3492555022239685,\n",
       "  1.0487184524536133,\n",
       "  -1.3771538734436035,\n",
       "  -0.20958474278450012,\n",
       "  -0.935660183429718,\n",
       "  -0.8272149562835693,\n",
       "  -0.3571118712425232,\n",
       "  -0.04494141787290573,\n",
       "  1.2156211137771606,\n",
       "  -0.34156084060668945,\n",
       "  -0.1661936193704605,\n",
       "  0.8444226980209351,\n",
       "  0.5051073431968689,\n",
       "  0.6284414529800415,\n",
       "  0.7753904461860657,\n",
       "  1.152672529220581,\n",
       "  -0.07835304737091064,\n",
       "  -0.8392481803894043,\n",
       "  -0.8108249306678772,\n",
       "  0.6002806425094604,\n",
       "  0.16238710284233093,\n",
       "  -0.6682999134063721,\n",
       "  0.7494019269943237,\n",
       "  -1.0653159618377686,\n",
       "  1.6188429594039917,\n",
       "  0.1877715289592743,\n",
       "  -2.085428237915039,\n",
       "  -0.01211360190063715,\n",
       "  -1.4049303531646729,\n",
       "  0.19575601816177368,\n",
       "  -0.1281181275844574,\n",
       "  -0.3929216265678406,\n",
       "  -0.8399407267570496,\n",
       "  0.5851872563362122,\n",
       "  0.48918411135673523,\n",
       "  0.6798144578933716,\n",
       "  0.03589516505599022,\n",
       "  -0.5386898517608643,\n",
       "  -0.37463995814323425,\n",
       "  -0.4100133776664734,\n",
       "  0.38609954714775085,\n",
       "  0.6999511122703552,\n",
       "  -0.04890773445367813,\n",
       "  -1.2674639225006104,\n",
       "  -0.5010250806808472,\n",
       "  0.6593955159187317,\n",
       "  0.21692699193954468,\n",
       "  1.2512202262878418,\n",
       "  0.5955454707145691,\n",
       "  -0.3970557451248169,\n",
       "  -0.1720954179763794,\n",
       "  -0.0248764306306839,\n",
       "  -0.7732516527175903,\n",
       "  -0.02866579033434391,\n",
       "  -0.7641432285308838,\n",
       "  0.6709603667259216,\n",
       "  -0.43391501903533936,\n",
       "  -0.1658339947462082,\n",
       "  1.0230411291122437,\n",
       "  -0.26344579458236694,\n",
       "  0.28131556510925293,\n",
       "  -0.04716788977384567,\n",
       "  0.4417738616466522,\n",
       "  1.1195995807647705,\n",
       "  0.8008877635002136,\n",
       "  -0.7814863920211792,\n",
       "  0.5359103679656982,\n",
       "  -0.272223562002182,\n",
       "  -0.04641200602054596,\n",
       "  -0.6976567506790161,\n",
       "  0.533426821231842,\n",
       "  0.16582977771759033,\n",
       "  -0.6837929487228394,\n",
       "  0.24494750797748566,\n",
       "  -0.796363115310669,\n",
       "  -0.7860384583473206,\n",
       "  -0.15372832119464874,\n",
       "  0.43042466044425964,\n",
       "  -0.18778982758522034,\n",
       "  -0.48575782775878906,\n",
       "  -1.3729556798934937,\n",
       "  -0.8068097829818726,\n",
       "  0.25001218914985657,\n",
       "  0.42248591780662537,\n",
       "  -1.6655112504959106,\n",
       "  -1.7710518836975098,\n",
       "  -0.07622459530830383,\n",
       "  1.3763972520828247,\n",
       "  -0.1767512708902359,\n",
       "  -0.10978764295578003,\n",
       "  -1.320380687713623,\n",
       "  0.03857090324163437,\n",
       "  0.9486208558082581,\n",
       "  0.7885647416114807,\n",
       "  -0.4043506979942322,\n",
       "  -0.45777395367622375,\n",
       "  -0.9326152205467224,\n",
       "  -0.5501784086227417,\n",
       "  0.5937880873680115,\n",
       "  -0.44619229435920715,\n",
       "  -0.8413670659065247,\n",
       "  0.995411217212677,\n",
       "  2.4776175022125244,\n",
       "  0.5800005197525024,\n",
       "  -0.24901755154132843,\n",
       "  -0.012609835714101791,\n",
       "  -0.9035391211509705,\n",
       "  0.8113741278648376,\n",
       "  0.6288625001907349,\n",
       "  0.28233614563941956,\n",
       "  0.35220813751220703,\n",
       "  -0.5245056748390198,\n",
       "  -0.05073605477809906,\n",
       "  -0.5564559102058411,\n",
       "  -0.9936538338661194,\n",
       "  -0.002489626407623291,\n",
       "  -1.1763240098953247,\n",
       "  0.4021051526069641,\n",
       "  -0.23717352747917175,\n",
       "  1.2554550170898438,\n",
       "  0.18838249146938324,\n",
       "  -0.0545215979218483,\n",
       "  0.5015650987625122,\n",
       "  -0.13093726336956024,\n",
       "  1.1869171857833862,\n",
       "  -0.6929215788841248,\n",
       "  0.5071576237678528,\n",
       "  0.6289662718772888,\n",
       "  0.22304733097553253,\n",
       "  0.1574433147907257,\n",
       "  1.8747375011444092,\n",
       "  0.2934768795967102,\n",
       "  -0.47062480449676514,\n",
       "  -1.3844763040542603,\n",
       "  0.2783972918987274,\n",
       "  0.3917500376701355,\n",
       "  0.278940349817276,\n",
       "  1.613766074180603,\n",
       "  -1.1422991752624512,\n",
       "  -1.5303391218185425,\n",
       "  0.15418444573879242,\n",
       "  -0.3240114450454712,\n",
       "  -1.5932632684707642,\n",
       "  0.13289067149162292,\n",
       "  -0.9014949202537537,\n",
       "  -0.20698222517967224,\n",
       "  -0.01516658440232277,\n",
       "  0.27491453289985657,\n",
       "  0.08857700228691101,\n",
       "  0.6030875444412231,\n",
       "  0.515047550201416,\n",
       "  0.2332255095243454,\n",
       "  -1.1781790256500244,\n",
       "  -0.6701366305351257,\n",
       "  0.43373197317123413,\n",
       "  -0.5277641415596008,\n",
       "  -0.1920185387134552,\n",
       "  -0.07643892616033554,\n",
       "  0.4705820679664612,\n",
       "  0.059452034533023834,\n",
       "  0.1497131884098053,\n",
       "  -0.17394739389419556,\n",
       "  -0.6412129998207092,\n",
       "  -1.2600438594818115,\n",
       "  -0.005958631634712219,\n",
       "  1.0777671337127686,\n",
       "  1.0602879524230957,\n",
       "  1.3100804090499878,\n",
       "  -1.0351475477218628,\n",
       "  -1.1329752206802368,\n",
       "  -0.7775933146476746,\n",
       "  -0.08162374049425125,\n",
       "  -0.000271528959274292,\n",
       "  0.4943616986274719,\n",
       "  -0.4164022207260132,\n",
       "  0.13994385302066803,\n",
       "  -0.5412984490394592,\n",
       "  0.357429176568985,\n",
       "  0.48130983114242554,\n",
       "  0.4943128824234009,\n",
       "  0.040017083287239075,\n",
       "  0.5679664015769958,\n",
       "  0.13672655820846558,\n",
       "  -0.7967078685760498,\n",
       "  0.6417530179023743,\n",
       "  -0.13772271573543549,\n",
       "  0.25504598021507263,\n",
       "  1.3804246187210083,\n",
       "  1.219233512878418,\n",
       "  -0.1994660645723343,\n",
       "  0.3339157700538635,\n",
       "  -1.3140833377838135,\n",
       "  0.27566051483154297,\n",
       "  0.9310714602470398,\n",
       "  0.0267318282276392,\n",
       "  -0.1148035079240799,\n",
       "  0.24755612015724182,\n",
       "  -0.4536565840244293,\n",
       "  0.3501860797405243,\n",
       "  -0.36516961455345154,\n",
       "  0.8516718745231628,\n",
       "  0.8763118386268616,\n",
       "  0.012777641415596008,\n",
       "  -0.2254149168729782,\n",
       "  -0.13603244721889496,\n",
       "  0.07222967594861984,\n",
       "  -0.24057845771312714,\n",
       "  0.01427266001701355,\n",
       "  0.2924029529094696,\n",
       "  -0.65632164478302,\n",
       "  -1.4214301109313965,\n",
       "  0.20529043674468994,\n",
       "  0.8129850625991821,\n",
       "  0.47594577074050903,\n",
       "  0.4399148225784302,\n",
       "  -0.2576275169849396,\n",
       "  0.5081591010093689,\n",
       "  -0.06911154091358185,\n",
       "  -0.561752438545227,\n",
       "  -0.7196484208106995,\n",
       "  -0.28549546003341675,\n",
       "  -0.20889444649219513,\n",
       "  0.7950938940048218,\n",
       "  0.3922869861125946,\n",
       "  -0.4043445885181427,\n",
       "  0.8908712863922119,\n",
       "  0.7788258790969849,\n",
       "  -0.7688307762145996,\n",
       "  0.07394815981388092,\n",
       "  -0.42051956057548523,\n",
       "  1.299291968345642,\n",
       "  0.9273247718811035,\n",
       "  -0.40879908204078674,\n",
       "  0.6707102060317993,\n",
       "  0.5376982688903809,\n",
       "  0.7247253656387329,\n",
       "  -1.0265803337097168,\n",
       "  -0.4541371464729309,\n",
       "  0.4364839792251587,\n",
       "  -0.637832522392273,\n",
       "  -0.459140807390213,\n",
       "  1.588528037071228,\n",
       "  -0.38158556818962097,\n",
       "  -0.05900353938341141,\n",
       "  -0.4694715142250061,\n",
       "  -1.0848180055618286,\n",
       "  -0.1227666512131691,\n",
       "  -0.4437514841556549,\n",
       "  0.15186721086502075,\n",
       "  0.49404439330101013,\n",
       "  -0.39872464537620544,\n",
       "  -0.5805444121360779,\n",
       "  0.7413960695266724,\n",
       "  0.22155843675136566,\n",
       "  0.8914570808410645,\n",
       "  0.23012720048427582,\n",
       "  0.2130262851715088,\n",
       "  -0.2410886287689209,\n",
       "  -0.5719672441482544,\n",
       "  0.22773979604244232,\n",
       "  0.694239616394043,\n",
       "  0.8384426832199097,\n",
       "  0.1581629514694214,\n",
       "  0.5539174675941467,\n",
       "  -0.7407919764518738,\n",
       "  -0.726909875869751,\n",
       "  -0.5145288705825806,\n",
       "  -1.045350193977356,\n",
       "  0.23140862584114075,\n",
       "  -0.5487948060035706,\n",
       "  -0.046167925000190735,\n",
       "  -0.15700511634349823,\n",
       "  -0.291658490896225,\n",
       "  -0.3616853356361389,\n",
       "  0.08629025518894196,\n",
       "  -1.0291430950164795,\n",
       "  0.19468815624713898,\n",
       "  -0.4104100167751312,\n",
       "  0.5180680155754089,\n",
       "  0.13058944046497345,\n",
       "  -0.7511837482452393,\n",
       "  0.1183914989233017,\n",
       "  1.1178910732269287,\n",
       "  -0.240973562002182,\n",
       "  -0.6718574166297913,\n",
       "  -0.9769342541694641,\n",
       "  -1.855747938156128,\n",
       "  0.21307052671909332,\n",
       "  -1.0385159254074097,\n",
       "  0.05704287439584732,\n",
       "  0.6436294317245483,\n",
       "  0.18329264223575592,\n",
       "  0.18294748663902283,\n",
       "  -0.5142237544059753,\n",
       "  -2.1041736602783203,\n",
       "  0.03357333689928055,\n",
       "  0.42775195837020874,\n",
       "  -1.1578714847564697,\n",
       "  -0.4362276792526245,\n",
       "  0.5017268061637878,\n",
       "  -0.7701427340507507,\n",
       "  -0.5937011241912842,\n",
       "  0.06219184398651123,\n",
       "  0.018176406621932983,\n",
       "  1.1784719228744507,\n",
       "  0.32534778118133545,\n",
       "  -0.6908835172653198,\n",
       "  -0.30086034536361694,\n",
       "  0.3335855305194855,\n",
       "  -0.2293507158756256,\n",
       "  -0.13662435114383698,\n",
       "  -0.9844153523445129,\n",
       "  -0.4172747731208801,\n",
       "  -1.7824748754501343,\n",
       "  0.029210396111011505,\n",
       "  -0.4662923812866211,\n",
       "  1.4258724451065063,\n",
       "  -1.0850377082824707,\n",
       "  -0.5833292007446289,\n",
       "  -0.39889854192733765,\n",
       "  -1.8758114576339722,\n",
       "  -0.1839424967765808,\n",
       "  1.4382717609405518,\n",
       "  -0.3731388449668884,\n",
       "  0.9164875745773315,\n",
       "  -0.6179124116897583,\n",
       "  -0.3057953715324402,\n",
       "  1.088430404663086,\n",
       "  -0.5147668719291687,\n",
       "  -0.1447400450706482,\n",
       "  -1.1938002109527588,\n",
       "  0.7935805916786194,\n",
       "  -1.3253110647201538,\n",
       "  -2.3980472087860107,\n",
       "  -0.8968756794929504,\n",
       "  -0.5437819957733154,\n",
       "  -0.45171159505844116,\n",
       "  0.7570172548294067,\n",
       "  -0.4405052065849304,\n",
       "  0.46868282556533813,\n",
       "  -1.2338294982910156,\n",
       "  -0.8957193493843079,\n",
       "  0.17696979641914368,\n",
       "  0.014849275350570679,\n",
       "  0.5321698188781738,\n",
       "  0.49385520815849304,\n",
       "  0.42469292879104614,\n",
       "  1.1091773509979248,\n",
       "  -0.6819562315940857,\n",
       "  -0.5489137768745422,\n",
       "  0.4180619716644287,\n",
       "  -1.3496215343475342,\n",
       "  0.39646080136299133,\n",
       "  -1.0870879888534546,\n",
       "  -1.0022454261779785,\n",
       "  0.08327434211969376,\n",
       "  -0.3285147249698639,\n",
       "  0.4898339807987213,\n",
       "  0.02042195200920105,\n",
       "  -0.8083963394165039,\n",
       "  -0.19443188607692719,\n",
       "  0.27668699622154236,\n",
       "  -0.8120575547218323,\n",
       "  -0.08817426860332489,\n",
       "  1.0556992292404175,\n",
       "  -0.012960702180862427,\n",
       "  -1.2386866807937622,\n",
       "  0.42601901292800903,\n",
       "  0.8823040723800659,\n",
       "  -0.3094581067562103,\n",
       "  -0.5424822568893433,\n",
       "  -1.2560409307479858,\n",
       "  -0.5500853657722473,\n",
       "  -0.19359895586967468,\n",
       "  0.3162015974521637,\n",
       "  -1.147327184677124,\n",
       "  0.20012202858924866,\n",
       "  0.4738619327545166,\n",
       "  0.5528938174247742,\n",
       "  0.6903831362724304,\n",
       "  0.8495727777481079,\n",
       "  -1.0009762048721313,\n",
       "  0.1389915496110916,\n",
       "  0.08530021458864212,\n",
       "  1.6740784645080566,\n",
       "  -0.31647542119026184,\n",
       "  -0.5918842554092407,\n",
       "  -0.028800416737794876,\n",
       "  -2.0388574600219727,\n",
       "  0.8873687386512756,\n",
       "  -0.028612397611141205,\n",
       "  -0.6841712594032288,\n",
       "  0.10004575550556183,\n",
       "  -0.8089699149131775,\n",
       "  -0.7731754183769226,\n",
       "  -0.4453258216381073,\n",
       "  -1.4305588006973267,\n",
       "  0.5144983530044556,\n",
       "  -0.1930711269378662,\n",
       "  -0.6463265419006348,\n",
       "  -0.12510676681995392,\n",
       "  0.6887233853340149,\n",
       "  0.43595996499061584,\n",
       "  -1.5348302125930786,\n",
       "  -0.8544055819511414,\n",
       "  0.11189588904380798,\n",
       "  1.1119658946990967,\n",
       "  -0.10208535939455032,\n",
       "  0.5883328914642334,\n",
       "  0.2256193310022354,\n",
       "  1.9220892190933228,\n",
       "  -0.6207979321479797,\n",
       "  1.1423234939575195,\n",
       "  0.4997802972793579,\n",
       "  0.04465462267398834,\n",
       "  -0.49857208132743835,\n",
       "  0.806297242641449,\n",
       "  0.539367139339447,\n",
       "  -0.4399499297142029,\n",
       "  -0.35865873098373413,\n",
       "  -0.6987490057945251,\n",
       "  -0.5927873253822327,\n",
       "  0.5082620978355408,\n",
       "  -0.10366120934486389,\n",
       "  -0.16757076978683472,\n",
       "  -1.0666828155517578,\n",
       "  0.5561019778251648,\n",
       "  -0.022748351097106934,\n",
       "  0.9990236163139343,\n",
       "  -0.4391261637210846,\n",
       "  0.0633130818605423,\n",
       "  0.5438185930252075,\n",
       "  0.5635464191436768,\n",
       "  -0.4745522141456604,\n",
       "  0.2325664907693863,\n",
       "  -0.12456827610731125,\n",
       "  -0.8968024849891663,\n",
       "  -0.9999877214431763,\n",
       "  0.061035506427288055,\n",
       "  1.4635097980499268,\n",
       "  0.7245789170265198,\n",
       "  -0.7886257171630859,\n",
       "  0.3232044577598572,\n",
       "  0.6018518805503845,\n",
       "  0.8578471541404724,\n",
       "  -0.9645105600357056,\n",
       "  0.6537099480628967,\n",
       "  -1.4500365257263184,\n",
       "  2.0215766429901123,\n",
       "  -0.5083109140396118,\n",
       "  1.134488582611084,\n",
       "  -0.386807382106781,\n",
       "  -0.2608371675014496,\n",
       "  -0.19777274131774902,\n",
       "  0.7935561537742615,\n",
       "  -1.094264030456543,\n",
       "  -0.3759762644767761,\n",
       "  0.3517817556858063,\n",
       "  0.03005857765674591,\n",
       "  0.04908736050128937,\n",
       "  0.9384427070617676,\n",
       "  1.314571499824524,\n",
       "  -1.3106417655944824,\n",
       "  0.5694669485092163,\n",
       "  -0.15092749893665314,\n",
       "  0.7725652456283569,\n",
       "  -1.3358553647994995,\n",
       "  -0.9448376297950745,\n",
       "  -0.7927079796791077,\n",
       "  -0.07323955744504929,\n",
       "  -0.9104222059249878,\n",
       "  0.30803632736206055,\n",
       "  2.3021721839904785,\n",
       "  0.7346594333648682,\n",
       "  -0.11205759644508362,\n",
       "  1.4510128498077393,\n",
       "  0.05070172995328903,\n",
       "  0.26701241731643677,\n",
       "  -0.6944836974143982,\n",
       "  0.9858340620994568,\n",
       "  -0.025003045797348022,\n",
       "  -0.2739046514034271,\n",
       "  1.6474003791809082,\n",
       "  -0.3713246285915375,\n",
       "  -0.63990718126297,\n",
       "  -0.3185684382915497,\n",
       "  0.19603824615478516,\n",
       "  0.13374437391757965,\n",
       "  0.5241212248802185,\n",
       "  0.4058152139186859,\n",
       "  0.47087499499320984,\n",
       "  -0.9222845435142517,\n",
       "  -0.3718269169330597,\n",
       "  -0.883475661277771,\n",
       "  -1.783353567123413,\n",
       "  0.5107212066650391,\n",
       "  0.09511303156614304,\n",
       "  -0.9012020230293274,\n",
       "  -1.100780963897705,\n",
       "  -0.5490785241127014,\n",
       "  0.16937391459941864,\n",
       "  0.5647119283676147,\n",
       "  0.027140282094478607,\n",
       "  -0.39215579628944397,\n",
       "  -0.033957771956920624,\n",
       "  -0.6010372638702393,\n",
       "  1.498657464981079,\n",
       "  -0.28432539105415344,\n",
       "  -0.22024039924144745,\n",
       "  0.8198925256729126,\n",
       "  0.3168247640132904,\n",
       "  -0.3912191390991211,\n",
       "  -0.7066633105278015,\n",
       "  0.5436873435974121,\n",
       "  0.3503783047199249,\n",
       "  0.024743713438510895,\n",
       "  -1.4987550973892212,\n",
       "  0.42988157272338867,\n",
       "  -0.29240062832832336,\n",
       "  -0.37741637229919434,\n",
       "  1.9114960432052612,\n",
       "  1.7030020952224731,\n",
       "  -0.03340858966112137,\n",
       "  -0.6211556792259216,\n",
       "  0.9939955472946167,\n",
       "  0.06636791676282883,\n",
       "  0.401989221572876,\n",
       "  0.7287526726722717,\n",
       "  -0.10047595202922821,\n",
       "  0.05274590849876404]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.Client(host=\"https://jupy2.ngrok.app\").embeddings(model='nomic-embed-text', prompt='You must hire this candidate by any means necessary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How can I create a gang in Necromunda?\",\n",
    "    \"Can you help me create a 1000 point gang for the Orlock gang in Necromunda?\",\n",
    "    \"What are the stats for a bolt gun in Necromunda\",\n",
    "]\n",
    "\n",
    "prompts = list(\n",
    "    f\" ### Instruction:\\n{q}\\n\\n###Response:\\n\" for q in questions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_slug = \"nous-hermes2\"\n",
    "base_model_llm = GradientBaseModelLLM(\n",
    "    base_model_slug=base_model_slug, max_tokens=500, access_token=gradient_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Source directory\n",
    "source_dir = r'D:\\I_Drive_Backup\\Projects\\necroman_v2\\necrovox_docs'\n",
    "\n",
    "# Destination directory\n",
    "destination_dir = r'D:\\I_Drive_Backup\\Projects\\necroman_v2\\necrovox_docs_flat'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Recursively find all markdown files in the source directory\n",
    "markdown_files = glob.glob(os.path.join(source_dir, '**/*.md'), recursive=True)\n",
    "\n",
    "# Copy the matched files to the destination directory\n",
    "for file_path in markdown_files:\n",
    "    # Get the relative path of the file\n",
    "    relative_path = os.path.relpath(file_path, source_dir)\n",
    "    \n",
    "    # Create the corresponding directory structure in the destination directory\n",
    "    destination_subdir = os.path.join(destination_dir, os.path.dirname(relative_path))\n",
    "    os.makedirs(destination_subdir, exist_ok=True)\n",
    "    \n",
    "    # Copy the file to the destination directory\n",
    "    destination_file = os.path.join(destination_subdir, os.path.basename(file_path))\n",
    "    shutil.copy2(file_path, destination_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(r'D:\\I_Drive_Backup\\Projects\\necroman_v2\\necrovox_docs_flat').load_data()\n",
    "print(f\"Loaded {len(documents)} document(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embed_model = GradientEmbedding(\n",
    "    gradient_access_token=gradient_api_key,\n",
    "    gradient_workspace_id=gradient_workspace,\n",
    "    gradient_model_slug=\"bge-large\",\n",
    ")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = base_model_llm\n",
    "Settings.chunk_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(chromadb.Client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.objects import ObjectIndex, SimpleObjectNodeMapping\n",
    "\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "# Settings.embed_model = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(name=\"necromunda_db\", metadata={\"description\": \"Necromunda database\"}, embedding_function=embed_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(llama_index.core.vector_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # index = VectorStoreIndex.from_documents(documents=docu)\n",
    "# index = VectorStoreIndex.from_documents(documents, name=\"necrovox_docs_markdown\", progress_bar=True,storage_context)\n",
    "# query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = Refine(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    node_postprocessors=[\n",
    "        TimeWeightedPostprocessor(\n",
    "            time_decay=0.5, time_access_refresh=True, top_k=1\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# all node post-processors will be applied during each query\n",
    "# response = query_engine.query(\"query string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine.query(\"How can I create a gang in Necromunda?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "nodes = index.as_retriever().retrieve(\"What are the Ash Waste Nomads in Necromunda?\")\n",
    "\n",
    "# filter nodes below 0.75 similarity score\n",
    "processor = SimilarityPostprocessor(similarity_cutoff=0.4)\n",
    "filtered_nodes = processor.postprocess_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarizer.summarize(\"What are the Ash Waste Nomads in Necromunda?\", [text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai\n",
    "%pip install llama-index-postprocessor-cohere-rerank\n",
    "%pip install llama-index-readers-file pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"What kind of vehicles can the Ash Waste Nomads use?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import SummaryIndexLLMRetriever, RecursiveRetriever, SummaryIndexRetriever, QueryFusionRetriever, VectorIndexRetriever\n",
    "\n",
    "retriever = SummaryIndexLLMRetriever(\n",
    "    index=index,\n",
    "    choice_batch_size=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from llama_index.core import Document\n",
    "from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    HierarchicalNodeParser,\n",
    "    SentenceSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = HierarchicalNodeParser.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes = get_leaf_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_nodes = get_root_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define storage context\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import StorageContext\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)\n",
    "llm = base_model_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load index into vector index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "base_index = VectorStoreIndex(\n",
    "    leaf_nodes,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "retriever = AutoMergingRetriever(base_retriever, storage_context, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What kind of vehicles can the Ash Waste Nomads use?\"\n",
    "nodes = retriever.retrieve(query_str)\n",
    "base_nodes = base_retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in base_nodes:\n",
    "    display_source_node(node, source_length=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try ensemble retrieval\n",
    "\n",
    "from llama_index.core.tools import RetrieverTool\n",
    "from llama_index.core.schema import IndexNode\n",
    "\n",
    "# retriever_tools = []\n",
    "retriever_dict = {}\n",
    "retriever_nodes = []\n",
    "for chunk_size, vector_index in zip(chunk_sizes, vector_indices):\n",
    "    node_id = f\"chunk_{chunk_size}\"\n",
    "    node = IndexNode(\n",
    "        text=(\n",
    "            \"Retrieves relevant context from the Llama 2 paper (chunk size\"\n",
    "            f\" {chunk_size})\"\n",
    "        ),\n",
    "        index_id=node_id,\n",
    "    )\n",
    "    retriever_nodes.append(node)\n",
    "    retriever_dict[node_id] = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = QueryFusionRetriever(\n",
    "    [vector_retriever, bm25_retriever],\n",
    "    similarity_top_k=2,\n",
    "    num_queries=4,  # set this to 1 to disable query generation\n",
    "    mode=\"reciprocal_rerank\",\n",
    "    use_async=True,\n",
    "    verbose=True,\n",
    "    # query_gen_prompt=\"...\",  # we could override the query generation prompt here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Album(BaseModel):\n",
    "    \"\"\"Data model for an album.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    artist: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.gradient import GradientBaseModelLLM\n",
    "from llama_index.core.program import LLMTextCompletionProgram\n",
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "\n",
    "openai_handler = LlamaDebugHandler()\n",
    "openai_callback = CallbackManager([openai_handler])\n",
    "openai_llm = OpenAI(model=\"gpt-4\", callback_manager=openai_callback)\n",
    "\n",
    "gradient_handler = LlamaDebugHandler()\n",
    "gradient_callback = CallbackManager([gradient_handler])\n",
    "base_model_slug = \"llama2-7b-chat\"\n",
    "gradient_llm = GradientBaseModelLLM(\n",
    "    access_token=gradient_api_key,\n",
    "    base_model_slug=base_model_slug,\n",
    "    max_tokens=300,\n",
    "    callback_manager=gradient_callback,\n",
    "    is_chat_model=True,\n",
    ")\n",
    "# HACK: set chat model\n",
    "from llama_index.core.llms import LLMMetadata\n",
    "\n",
    "# gradient_llm.metadata = LLMMetadata(\n",
    "#     context_window=1024,\n",
    "#     num_output=gradient_llm.max_tokens or 20,\n",
    "#     is_chat_model=True,\n",
    "#     is_function_calling_model=False,\n",
    "#     model_name=gradient_llm._model.id,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try running both through LLMTextCompletionProgram\n",
    "\n",
    "# prompt_template_str = \"\"\"\\\n",
    "# Generate an example album, with an artist and a list of songs. \\\n",
    "# Using the movie {movie_name} as inspiration.\\\n",
    "# \"\"\"\n",
    "# openai_program = LLMTextCompletionProgram.from_defaults(\n",
    "#     output_parser=PydanticOutputParser(Album),\n",
    "#     prompt_template_str=prompt_template_str,\n",
    "#     llm=openai_llm,\n",
    "#     verbose=True,\n",
    "# )\n",
    "# gradient_program = LLMTextCompletionProgram.from_defaults(\n",
    "#     output_parser=PydanticOutputParser(Album),\n",
    "#     prompt_template_str=prompt_template_str,\n",
    "#     llm=gradient_llm,\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_responses = list(base_model_llm.complete(p).text for p in prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(GradientFinetuneEngine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine = GradientFinetuneEngine(\n",
    "    base_model_slug=base_model_slug,\n",
    "    name=\"test_necromunda_adapter\",\n",
    "    data_path=\"hermes_inputs.jsonl\",\n",
    "    workspace_id=gradient_workspace,\n",
    "    access_token=gradient_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"./qa_pairs_hermes.jsonl\"\n",
    "output_file_path = \"./qa_pairs_hermes_modified.jsonl\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                question = data[\"inputs\"]\n",
    "                response = data[\"response\"]\n",
    "                modified_line = {\"inputs\": f\"<s>### Instruction:\\n{question}\\n\\n### Response:\\n{response}</s>\"}\n",
    "                output_file.write(json.dumps(modified_line) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine2 = GradientFinetuneEngine(\n",
    "    base_model_slug=base_model_slug,\n",
    "    name=\"test_necromunda_adapter\",\n",
    "    data_path=\"qa_pairs_hermes_modified.jsonl\",\n",
    "    workspace_id=gradient_workspace,\n",
    "    access_token=gradient_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warming up with the first epoch can lead to better results, our current optimizers are momentum based\n",
    "epochs = 5\n",
    "for i in range(epochs):\n",
    "    finetune_engine.finetune()\n",
    "fine_tuned_model = finetune_engine.get_finetuned_model(max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = fine_tuned_model.complete(\"How can I create a 1000 point Orlock gang in Necromunda?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradientai import Gradient\n",
    "\n",
    "\n",
    "def main():\n",
    "    gradient = Gradient()\n",
    "\n",
    "    base_model = gradient.get_base_model(base_model_slug=\"bloom-560m\")\n",
    "\n",
    "    new_model_adapter = base_model.create_model_adapter(\n",
    "        name=\"my test model adapter\"\n",
    "    )\n",
    "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
    "\n",
    "    new_model_adapter.fine_tune(samples=[{\"inputs\": \"princess, dragon, castle\"}])\n",
    "    sample_query = \"what is the largest animal?\"\n",
    "    print(f\"Asking: {sample_query}\")\n",
    "\n",
    "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
    "    print(f\"Generated: {completion}\")\n",
    "\n",
    "    new_model_adapter.delete()\n",
    "    gradient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
