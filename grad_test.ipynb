{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-gradient llama-index\n",
    "%pip install llama-index-finetuning\n",
    "%pip install llama-index-llms-gradient\n",
    "%pip install llama-index-embeddings-gradient\n",
    "%pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "import os\n",
    "gradient_api_key = os.getenv(\"GRADIENT_API_KEY\")\n",
    "gradient_workspace = os.getenv(\"GRADIENT_WORKSPACE_ID\")\n",
    "from llama_index.llms.gradient import GradientBaseModelLLM\n",
    "from llama_index.finetuning import GradientFinetuneEngine\n",
    "os.environ[\"GRADIENT_API_KEY\"] = gradient_api_key\n",
    "os.environ[\"GRADIENT_WORKSPACE_ID\"] = gradient_workspace\n",
    "\n",
    "\n",
    "from llama_index.core.response_synthesizers import Refine\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "from llama_index.core.data_structs import Node\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.core.postprocessor import TimeWeightedPostprocessor\n",
    "\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "# from llama_index.core.vector_stores\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "\n",
    "from llama_index.embeddings.gradient import GradientEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding': [-0.8417011499404907,\n",
       "  -0.38018935918807983,\n",
       "  -2.2074687480926514,\n",
       "  0.4917255938053131,\n",
       "  0.3621918261051178,\n",
       "  0.2340126782655716,\n",
       "  -0.45399677753448486,\n",
       "  1.6895288228988647,\n",
       "  1.041884183883667,\n",
       "  1.5690504312515259,\n",
       "  -0.9136074185371399,\n",
       "  0.8415181040763855,\n",
       "  -0.76592618227005,\n",
       "  -0.14406271278858185,\n",
       "  -0.6489260196685791,\n",
       "  0.3822888135910034,\n",
       "  0.9709786772727966,\n",
       "  -2.15132999420166,\n",
       "  0.567293107509613,\n",
       "  0.15537816286087036,\n",
       "  -0.14207956194877625,\n",
       "  -0.7902367115020752,\n",
       "  0.522583544254303,\n",
       "  -0.5737978219985962,\n",
       "  0.89002925157547,\n",
       "  -1.1292469501495361,\n",
       "  0.5042896866798401,\n",
       "  -0.34414201974868774,\n",
       "  0.7126677632331848,\n",
       "  -0.4482181668281555,\n",
       "  0.5081705451011658,\n",
       "  0.5893732309341431,\n",
       "  0.750646710395813,\n",
       "  -1.4699534177780151,\n",
       "  -0.5100438594818115,\n",
       "  -0.9757871031761169,\n",
       "  -0.8095923066139221,\n",
       "  0.3274163603782654,\n",
       "  -0.44592535495758057,\n",
       "  -0.6402671933174133,\n",
       "  -0.2991487383842468,\n",
       "  0.8135250806808472,\n",
       "  0.3214851915836334,\n",
       "  -1.742933750152588,\n",
       "  0.04424731060862541,\n",
       "  0.1767583191394806,\n",
       "  0.8593596816062927,\n",
       "  1.17354154586792,\n",
       "  -0.1259915679693222,\n",
       "  -1.0856235027313232,\n",
       "  -0.6992676854133606,\n",
       "  -0.8484439253807068,\n",
       "  -0.10795703530311584,\n",
       "  -0.44565799832344055,\n",
       "  -0.3380918502807617,\n",
       "  0.2886258065700531,\n",
       "  1.2102024555206299,\n",
       "  1.224359154701233,\n",
       "  -0.824627697467804,\n",
       "  -0.1998443752527237,\n",
       "  2.3671953678131104,\n",
       "  0.8806930780410767,\n",
       "  -0.9435195922851562,\n",
       "  2.0540881156921387,\n",
       "  -0.4508725702762604,\n",
       "  -1.1721258163452148,\n",
       "  -0.38937634229660034,\n",
       "  0.7752256989479065,\n",
       "  -0.05295642465353012,\n",
       "  -0.5238955020904541,\n",
       "  -0.1129118800163269,\n",
       "  0.6754636764526367,\n",
       "  0.5380185842514038,\n",
       "  -0.34276601672172546,\n",
       "  0.08831766247749329,\n",
       "  1.0124480724334717,\n",
       "  -0.5789387822151184,\n",
       "  0.006821304559707642,\n",
       "  0.22172623872756958,\n",
       "  1.1436903476715088,\n",
       "  0.5863435864448547,\n",
       "  -0.33330482244491577,\n",
       "  2.5780813694000244,\n",
       "  0.7732089757919312,\n",
       "  0.8912984132766724,\n",
       "  -0.5224187970161438,\n",
       "  0.0424639955163002,\n",
       "  0.3073224127292633,\n",
       "  -0.17493286728858948,\n",
       "  0.5302537679672241,\n",
       "  0.021006222814321518,\n",
       "  1.3858431577682495,\n",
       "  -0.27497556805610657,\n",
       "  1.1916522979736328,\n",
       "  -0.6879911422729492,\n",
       "  -0.21014992892742157,\n",
       "  -1.526775598526001,\n",
       "  0.15189771354198456,\n",
       "  -0.29650941491127014,\n",
       "  -0.07747131586074829,\n",
       "  -0.8107516765594482,\n",
       "  -0.7743836045265198,\n",
       "  -1.5608493089675903,\n",
       "  -0.6104221940040588,\n",
       "  -0.3456820249557495,\n",
       "  1.2356356382369995,\n",
       "  0.6588526964187622,\n",
       "  -0.23730775713920593,\n",
       "  0.5604588389396667,\n",
       "  -1.1923112869262695,\n",
       "  -0.8408346772193909,\n",
       "  -0.030404865741729736,\n",
       "  -0.9483523964881897,\n",
       "  -1.4978764057159424,\n",
       "  -1.5958017110824585,\n",
       "  0.5474492907524109,\n",
       "  0.6175005435943604,\n",
       "  0.6433731317520142,\n",
       "  0.5800462961196899,\n",
       "  1.198291301727295,\n",
       "  -0.9166950583457947,\n",
       "  0.11138026416301727,\n",
       "  -0.35723087191581726,\n",
       "  1.5890650749206543,\n",
       "  0.3125762343406677,\n",
       "  1.2854526042938232,\n",
       "  -0.6645044088363647,\n",
       "  0.3247619867324829,\n",
       "  0.614185631275177,\n",
       "  0.1111680343747139,\n",
       "  0.6480899453163147,\n",
       "  -0.25158190727233887,\n",
       "  0.6511196494102478,\n",
       "  -0.09877043217420578,\n",
       "  -0.18361756205558777,\n",
       "  0.4858951270580292,\n",
       "  0.2187148928642273,\n",
       "  -0.0035452768206596375,\n",
       "  -1.0174273252487183,\n",
       "  0.3906150460243225,\n",
       "  -0.5568593740463257,\n",
       "  0.5275993943214417,\n",
       "  1.4046862125396729,\n",
       "  0.4882352650165558,\n",
       "  0.021662190556526184,\n",
       "  0.03965705633163452,\n",
       "  0.41374170780181885,\n",
       "  0.7865815758705139,\n",
       "  -0.4841468930244446,\n",
       "  1.2961677312850952,\n",
       "  -0.2931900918483734,\n",
       "  0.9517207145690918,\n",
       "  0.5657065510749817,\n",
       "  0.1358768492937088,\n",
       "  1.3818891048431396,\n",
       "  -0.9013179540634155,\n",
       "  0.5767999887466431,\n",
       "  -0.24297045171260834,\n",
       "  0.19873686134815216,\n",
       "  -0.3815580904483795,\n",
       "  1.9992188215255737,\n",
       "  -0.7873321175575256,\n",
       "  -0.6525169610977173,\n",
       "  0.5406394600868225,\n",
       "  0.21760888397693634,\n",
       "  -1.3228702545166016,\n",
       "  0.15935133397579193,\n",
       "  1.308152198791504,\n",
       "  -0.02416020818054676,\n",
       "  1.045106053352356,\n",
       "  0.48852816224098206,\n",
       "  -1.5464973449707031,\n",
       "  -0.22345617413520813,\n",
       "  0.1449947953224182,\n",
       "  0.6780936121940613,\n",
       "  -0.6152915954589844,\n",
       "  0.8675615787506104,\n",
       "  -0.7852086424827576,\n",
       "  -0.713814914226532,\n",
       "  -0.27035632729530334,\n",
       "  0.9752989411354065,\n",
       "  -0.24173782765865326,\n",
       "  0.10679765045642853,\n",
       "  0.13379301130771637,\n",
       "  -0.7352513074874878,\n",
       "  0.3454363942146301,\n",
       "  -0.10232943296432495,\n",
       "  0.09908469021320343,\n",
       "  0.8045200109481812,\n",
       "  0.51617032289505,\n",
       "  -0.19646157324314117,\n",
       "  -0.10655508935451508,\n",
       "  0.13849309086799622,\n",
       "  0.29823410511016846,\n",
       "  0.29219546914100647,\n",
       "  0.2607807219028473,\n",
       "  1.6095678806304932,\n",
       "  -0.42859405279159546,\n",
       "  0.5673663020133972,\n",
       "  -0.03147424757480621,\n",
       "  -0.1730995774269104,\n",
       "  0.7566755414009094,\n",
       "  -0.30775564908981323,\n",
       "  1.2066876888275146,\n",
       "  -0.8259457349777222,\n",
       "  0.6628606915473938,\n",
       "  0.1077190563082695,\n",
       "  -0.25825831294059753,\n",
       "  -0.3929887115955353,\n",
       "  -0.5770624279975891,\n",
       "  0.632230818271637,\n",
       "  0.08466559648513794,\n",
       "  0.8077861070632935,\n",
       "  -0.16202402114868164,\n",
       "  0.4539174735546112,\n",
       "  -0.6852940320968628,\n",
       "  -0.0851171538233757,\n",
       "  -0.12123504281044006,\n",
       "  -1.1651939153671265,\n",
       "  0.25917741656303406,\n",
       "  0.837771475315094,\n",
       "  0.8349462151527405,\n",
       "  0.05591896176338196,\n",
       "  1.0194776058197021,\n",
       "  -0.4152367115020752,\n",
       "  0.0014382638037204742,\n",
       "  -1.8913350105285645,\n",
       "  -0.16461984813213348,\n",
       "  -0.2559341788291931,\n",
       "  1.0541858673095703,\n",
       "  0.887588381767273,\n",
       "  -0.9128385782241821,\n",
       "  1.294312834739685,\n",
       "  0.9265315532684326,\n",
       "  1.3040516376495361,\n",
       "  0.5376616716384888,\n",
       "  0.732145369052887,\n",
       "  0.6844672560691833,\n",
       "  0.3492555022239685,\n",
       "  1.0487184524536133,\n",
       "  -1.3771538734436035,\n",
       "  -0.20958474278450012,\n",
       "  -0.935660183429718,\n",
       "  -0.8272149562835693,\n",
       "  -0.3571118712425232,\n",
       "  -0.04494141787290573,\n",
       "  1.2156211137771606,\n",
       "  -0.34156084060668945,\n",
       "  -0.1661936193704605,\n",
       "  0.8444226980209351,\n",
       "  0.5051073431968689,\n",
       "  0.6284414529800415,\n",
       "  0.7753904461860657,\n",
       "  1.152672529220581,\n",
       "  -0.07835304737091064,\n",
       "  -0.8392481803894043,\n",
       "  -0.8108249306678772,\n",
       "  0.6002806425094604,\n",
       "  0.16238710284233093,\n",
       "  -0.6682999134063721,\n",
       "  0.7494019269943237,\n",
       "  -1.0653159618377686,\n",
       "  1.6188429594039917,\n",
       "  0.1877715289592743,\n",
       "  -2.085428237915039,\n",
       "  -0.01211360190063715,\n",
       "  -1.4049303531646729,\n",
       "  0.19575601816177368,\n",
       "  -0.1281181275844574,\n",
       "  -0.3929216265678406,\n",
       "  -0.8399407267570496,\n",
       "  0.5851872563362122,\n",
       "  0.48918411135673523,\n",
       "  0.6798144578933716,\n",
       "  0.03589516505599022,\n",
       "  -0.5386898517608643,\n",
       "  -0.37463995814323425,\n",
       "  -0.4100133776664734,\n",
       "  0.38609954714775085,\n",
       "  0.6999511122703552,\n",
       "  -0.04890773445367813,\n",
       "  -1.2674639225006104,\n",
       "  -0.5010250806808472,\n",
       "  0.6593955159187317,\n",
       "  0.21692699193954468,\n",
       "  1.2512202262878418,\n",
       "  0.5955454707145691,\n",
       "  -0.3970557451248169,\n",
       "  -0.1720954179763794,\n",
       "  -0.0248764306306839,\n",
       "  -0.7732516527175903,\n",
       "  -0.02866579033434391,\n",
       "  -0.7641432285308838,\n",
       "  0.6709603667259216,\n",
       "  -0.43391501903533936,\n",
       "  -0.1658339947462082,\n",
       "  1.0230411291122437,\n",
       "  -0.26344579458236694,\n",
       "  0.28131556510925293,\n",
       "  -0.04716788977384567,\n",
       "  0.4417738616466522,\n",
       "  1.1195995807647705,\n",
       "  0.8008877635002136,\n",
       "  -0.7814863920211792,\n",
       "  0.5359103679656982,\n",
       "  -0.272223562002182,\n",
       "  -0.04641200602054596,\n",
       "  -0.6976567506790161,\n",
       "  0.533426821231842,\n",
       "  0.16582977771759033,\n",
       "  -0.6837929487228394,\n",
       "  0.24494750797748566,\n",
       "  -0.796363115310669,\n",
       "  -0.7860384583473206,\n",
       "  -0.15372832119464874,\n",
       "  0.43042466044425964,\n",
       "  -0.18778982758522034,\n",
       "  -0.48575782775878906,\n",
       "  -1.3729556798934937,\n",
       "  -0.8068097829818726,\n",
       "  0.25001218914985657,\n",
       "  0.42248591780662537,\n",
       "  -1.6655112504959106,\n",
       "  -1.7710518836975098,\n",
       "  -0.07622459530830383,\n",
       "  1.3763972520828247,\n",
       "  -0.1767512708902359,\n",
       "  -0.10978764295578003,\n",
       "  -1.320380687713623,\n",
       "  0.03857090324163437,\n",
       "  0.9486208558082581,\n",
       "  0.7885647416114807,\n",
       "  -0.4043506979942322,\n",
       "  -0.45777395367622375,\n",
       "  -0.9326152205467224,\n",
       "  -0.5501784086227417,\n",
       "  0.5937880873680115,\n",
       "  -0.44619229435920715,\n",
       "  -0.8413670659065247,\n",
       "  0.995411217212677,\n",
       "  2.4776175022125244,\n",
       "  0.5800005197525024,\n",
       "  -0.24901755154132843,\n",
       "  -0.012609835714101791,\n",
       "  -0.9035391211509705,\n",
       "  0.8113741278648376,\n",
       "  0.6288625001907349,\n",
       "  0.28233614563941956,\n",
       "  0.35220813751220703,\n",
       "  -0.5245056748390198,\n",
       "  -0.05073605477809906,\n",
       "  -0.5564559102058411,\n",
       "  -0.9936538338661194,\n",
       "  -0.002489626407623291,\n",
       "  -1.1763240098953247,\n",
       "  0.4021051526069641,\n",
       "  -0.23717352747917175,\n",
       "  1.2554550170898438,\n",
       "  0.18838249146938324,\n",
       "  -0.0545215979218483,\n",
       "  0.5015650987625122,\n",
       "  -0.13093726336956024,\n",
       "  1.1869171857833862,\n",
       "  -0.6929215788841248,\n",
       "  0.5071576237678528,\n",
       "  0.6289662718772888,\n",
       "  0.22304733097553253,\n",
       "  0.1574433147907257,\n",
       "  1.8747375011444092,\n",
       "  0.2934768795967102,\n",
       "  -0.47062480449676514,\n",
       "  -1.3844763040542603,\n",
       "  0.2783972918987274,\n",
       "  0.3917500376701355,\n",
       "  0.278940349817276,\n",
       "  1.613766074180603,\n",
       "  -1.1422991752624512,\n",
       "  -1.5303391218185425,\n",
       "  0.15418444573879242,\n",
       "  -0.3240114450454712,\n",
       "  -1.5932632684707642,\n",
       "  0.13289067149162292,\n",
       "  -0.9014949202537537,\n",
       "  -0.20698222517967224,\n",
       "  -0.01516658440232277,\n",
       "  0.27491453289985657,\n",
       "  0.08857700228691101,\n",
       "  0.6030875444412231,\n",
       "  0.515047550201416,\n",
       "  0.2332255095243454,\n",
       "  -1.1781790256500244,\n",
       "  -0.6701366305351257,\n",
       "  0.43373197317123413,\n",
       "  -0.5277641415596008,\n",
       "  -0.1920185387134552,\n",
       "  -0.07643892616033554,\n",
       "  0.4705820679664612,\n",
       "  0.059452034533023834,\n",
       "  0.1497131884098053,\n",
       "  -0.17394739389419556,\n",
       "  -0.6412129998207092,\n",
       "  -1.2600438594818115,\n",
       "  -0.005958631634712219,\n",
       "  1.0777671337127686,\n",
       "  1.0602879524230957,\n",
       "  1.3100804090499878,\n",
       "  -1.0351475477218628,\n",
       "  -1.1329752206802368,\n",
       "  -0.7775933146476746,\n",
       "  -0.08162374049425125,\n",
       "  -0.000271528959274292,\n",
       "  0.4943616986274719,\n",
       "  -0.4164022207260132,\n",
       "  0.13994385302066803,\n",
       "  -0.5412984490394592,\n",
       "  0.357429176568985,\n",
       "  0.48130983114242554,\n",
       "  0.4943128824234009,\n",
       "  0.040017083287239075,\n",
       "  0.5679664015769958,\n",
       "  0.13672655820846558,\n",
       "  -0.7967078685760498,\n",
       "  0.6417530179023743,\n",
       "  -0.13772271573543549,\n",
       "  0.25504598021507263,\n",
       "  1.3804246187210083,\n",
       "  1.219233512878418,\n",
       "  -0.1994660645723343,\n",
       "  0.3339157700538635,\n",
       "  -1.3140833377838135,\n",
       "  0.27566051483154297,\n",
       "  0.9310714602470398,\n",
       "  0.0267318282276392,\n",
       "  -0.1148035079240799,\n",
       "  0.24755612015724182,\n",
       "  -0.4536565840244293,\n",
       "  0.3501860797405243,\n",
       "  -0.36516961455345154,\n",
       "  0.8516718745231628,\n",
       "  0.8763118386268616,\n",
       "  0.012777641415596008,\n",
       "  -0.2254149168729782,\n",
       "  -0.13603244721889496,\n",
       "  0.07222967594861984,\n",
       "  -0.24057845771312714,\n",
       "  0.01427266001701355,\n",
       "  0.2924029529094696,\n",
       "  -0.65632164478302,\n",
       "  -1.4214301109313965,\n",
       "  0.20529043674468994,\n",
       "  0.8129850625991821,\n",
       "  0.47594577074050903,\n",
       "  0.4399148225784302,\n",
       "  -0.2576275169849396,\n",
       "  0.5081591010093689,\n",
       "  -0.06911154091358185,\n",
       "  -0.561752438545227,\n",
       "  -0.7196484208106995,\n",
       "  -0.28549546003341675,\n",
       "  -0.20889444649219513,\n",
       "  0.7950938940048218,\n",
       "  0.3922869861125946,\n",
       "  -0.4043445885181427,\n",
       "  0.8908712863922119,\n",
       "  0.7788258790969849,\n",
       "  -0.7688307762145996,\n",
       "  0.07394815981388092,\n",
       "  -0.42051956057548523,\n",
       "  1.299291968345642,\n",
       "  0.9273247718811035,\n",
       "  -0.40879908204078674,\n",
       "  0.6707102060317993,\n",
       "  0.5376982688903809,\n",
       "  0.7247253656387329,\n",
       "  -1.0265803337097168,\n",
       "  -0.4541371464729309,\n",
       "  0.4364839792251587,\n",
       "  -0.637832522392273,\n",
       "  -0.459140807390213,\n",
       "  1.588528037071228,\n",
       "  -0.38158556818962097,\n",
       "  -0.05900353938341141,\n",
       "  -0.4694715142250061,\n",
       "  -1.0848180055618286,\n",
       "  -0.1227666512131691,\n",
       "  -0.4437514841556549,\n",
       "  0.15186721086502075,\n",
       "  0.49404439330101013,\n",
       "  -0.39872464537620544,\n",
       "  -0.5805444121360779,\n",
       "  0.7413960695266724,\n",
       "  0.22155843675136566,\n",
       "  0.8914570808410645,\n",
       "  0.23012720048427582,\n",
       "  0.2130262851715088,\n",
       "  -0.2410886287689209,\n",
       "  -0.5719672441482544,\n",
       "  0.22773979604244232,\n",
       "  0.694239616394043,\n",
       "  0.8384426832199097,\n",
       "  0.1581629514694214,\n",
       "  0.5539174675941467,\n",
       "  -0.7407919764518738,\n",
       "  -0.726909875869751,\n",
       "  -0.5145288705825806,\n",
       "  -1.045350193977356,\n",
       "  0.23140862584114075,\n",
       "  -0.5487948060035706,\n",
       "  -0.046167925000190735,\n",
       "  -0.15700511634349823,\n",
       "  -0.291658490896225,\n",
       "  -0.3616853356361389,\n",
       "  0.08629025518894196,\n",
       "  -1.0291430950164795,\n",
       "  0.19468815624713898,\n",
       "  -0.4104100167751312,\n",
       "  0.5180680155754089,\n",
       "  0.13058944046497345,\n",
       "  -0.7511837482452393,\n",
       "  0.1183914989233017,\n",
       "  1.1178910732269287,\n",
       "  -0.240973562002182,\n",
       "  -0.6718574166297913,\n",
       "  -0.9769342541694641,\n",
       "  -1.855747938156128,\n",
       "  0.21307052671909332,\n",
       "  -1.0385159254074097,\n",
       "  0.05704287439584732,\n",
       "  0.6436294317245483,\n",
       "  0.18329264223575592,\n",
       "  0.18294748663902283,\n",
       "  -0.5142237544059753,\n",
       "  -2.1041736602783203,\n",
       "  0.03357333689928055,\n",
       "  0.42775195837020874,\n",
       "  -1.1578714847564697,\n",
       "  -0.4362276792526245,\n",
       "  0.5017268061637878,\n",
       "  -0.7701427340507507,\n",
       "  -0.5937011241912842,\n",
       "  0.06219184398651123,\n",
       "  0.018176406621932983,\n",
       "  1.1784719228744507,\n",
       "  0.32534778118133545,\n",
       "  -0.6908835172653198,\n",
       "  -0.30086034536361694,\n",
       "  0.3335855305194855,\n",
       "  -0.2293507158756256,\n",
       "  -0.13662435114383698,\n",
       "  -0.9844153523445129,\n",
       "  -0.4172747731208801,\n",
       "  -1.7824748754501343,\n",
       "  0.029210396111011505,\n",
       "  -0.4662923812866211,\n",
       "  1.4258724451065063,\n",
       "  -1.0850377082824707,\n",
       "  -0.5833292007446289,\n",
       "  -0.39889854192733765,\n",
       "  -1.8758114576339722,\n",
       "  -0.1839424967765808,\n",
       "  1.4382717609405518,\n",
       "  -0.3731388449668884,\n",
       "  0.9164875745773315,\n",
       "  -0.6179124116897583,\n",
       "  -0.3057953715324402,\n",
       "  1.088430404663086,\n",
       "  -0.5147668719291687,\n",
       "  -0.1447400450706482,\n",
       "  -1.1938002109527588,\n",
       "  0.7935805916786194,\n",
       "  -1.3253110647201538,\n",
       "  -2.3980472087860107,\n",
       "  -0.8968756794929504,\n",
       "  -0.5437819957733154,\n",
       "  -0.45171159505844116,\n",
       "  0.7570172548294067,\n",
       "  -0.4405052065849304,\n",
       "  0.46868282556533813,\n",
       "  -1.2338294982910156,\n",
       "  -0.8957193493843079,\n",
       "  0.17696979641914368,\n",
       "  0.014849275350570679,\n",
       "  0.5321698188781738,\n",
       "  0.49385520815849304,\n",
       "  0.42469292879104614,\n",
       "  1.1091773509979248,\n",
       "  -0.6819562315940857,\n",
       "  -0.5489137768745422,\n",
       "  0.4180619716644287,\n",
       "  -1.3496215343475342,\n",
       "  0.39646080136299133,\n",
       "  -1.0870879888534546,\n",
       "  -1.0022454261779785,\n",
       "  0.08327434211969376,\n",
       "  -0.3285147249698639,\n",
       "  0.4898339807987213,\n",
       "  0.02042195200920105,\n",
       "  -0.8083963394165039,\n",
       "  -0.19443188607692719,\n",
       "  0.27668699622154236,\n",
       "  -0.8120575547218323,\n",
       "  -0.08817426860332489,\n",
       "  1.0556992292404175,\n",
       "  -0.012960702180862427,\n",
       "  -1.2386866807937622,\n",
       "  0.42601901292800903,\n",
       "  0.8823040723800659,\n",
       "  -0.3094581067562103,\n",
       "  -0.5424822568893433,\n",
       "  -1.2560409307479858,\n",
       "  -0.5500853657722473,\n",
       "  -0.19359895586967468,\n",
       "  0.3162015974521637,\n",
       "  -1.147327184677124,\n",
       "  0.20012202858924866,\n",
       "  0.4738619327545166,\n",
       "  0.5528938174247742,\n",
       "  0.6903831362724304,\n",
       "  0.8495727777481079,\n",
       "  -1.0009762048721313,\n",
       "  0.1389915496110916,\n",
       "  0.08530021458864212,\n",
       "  1.6740784645080566,\n",
       "  -0.31647542119026184,\n",
       "  -0.5918842554092407,\n",
       "  -0.028800416737794876,\n",
       "  -2.0388574600219727,\n",
       "  0.8873687386512756,\n",
       "  -0.028612397611141205,\n",
       "  -0.6841712594032288,\n",
       "  0.10004575550556183,\n",
       "  -0.8089699149131775,\n",
       "  -0.7731754183769226,\n",
       "  -0.4453258216381073,\n",
       "  -1.4305588006973267,\n",
       "  0.5144983530044556,\n",
       "  -0.1930711269378662,\n",
       "  -0.6463265419006348,\n",
       "  -0.12510676681995392,\n",
       "  0.6887233853340149,\n",
       "  0.43595996499061584,\n",
       "  -1.5348302125930786,\n",
       "  -0.8544055819511414,\n",
       "  0.11189588904380798,\n",
       "  1.1119658946990967,\n",
       "  -0.10208535939455032,\n",
       "  0.5883328914642334,\n",
       "  0.2256193310022354,\n",
       "  1.9220892190933228,\n",
       "  -0.6207979321479797,\n",
       "  1.1423234939575195,\n",
       "  0.4997802972793579,\n",
       "  0.04465462267398834,\n",
       "  -0.49857208132743835,\n",
       "  0.806297242641449,\n",
       "  0.539367139339447,\n",
       "  -0.4399499297142029,\n",
       "  -0.35865873098373413,\n",
       "  -0.6987490057945251,\n",
       "  -0.5927873253822327,\n",
       "  0.5082620978355408,\n",
       "  -0.10366120934486389,\n",
       "  -0.16757076978683472,\n",
       "  -1.0666828155517578,\n",
       "  0.5561019778251648,\n",
       "  -0.022748351097106934,\n",
       "  0.9990236163139343,\n",
       "  -0.4391261637210846,\n",
       "  0.0633130818605423,\n",
       "  0.5438185930252075,\n",
       "  0.5635464191436768,\n",
       "  -0.4745522141456604,\n",
       "  0.2325664907693863,\n",
       "  -0.12456827610731125,\n",
       "  -0.8968024849891663,\n",
       "  -0.9999877214431763,\n",
       "  0.061035506427288055,\n",
       "  1.4635097980499268,\n",
       "  0.7245789170265198,\n",
       "  -0.7886257171630859,\n",
       "  0.3232044577598572,\n",
       "  0.6018518805503845,\n",
       "  0.8578471541404724,\n",
       "  -0.9645105600357056,\n",
       "  0.6537099480628967,\n",
       "  -1.4500365257263184,\n",
       "  2.0215766429901123,\n",
       "  -0.5083109140396118,\n",
       "  1.134488582611084,\n",
       "  -0.386807382106781,\n",
       "  -0.2608371675014496,\n",
       "  -0.19777274131774902,\n",
       "  0.7935561537742615,\n",
       "  -1.094264030456543,\n",
       "  -0.3759762644767761,\n",
       "  0.3517817556858063,\n",
       "  0.03005857765674591,\n",
       "  0.04908736050128937,\n",
       "  0.9384427070617676,\n",
       "  1.314571499824524,\n",
       "  -1.3106417655944824,\n",
       "  0.5694669485092163,\n",
       "  -0.15092749893665314,\n",
       "  0.7725652456283569,\n",
       "  -1.3358553647994995,\n",
       "  -0.9448376297950745,\n",
       "  -0.7927079796791077,\n",
       "  -0.07323955744504929,\n",
       "  -0.9104222059249878,\n",
       "  0.30803632736206055,\n",
       "  2.3021721839904785,\n",
       "  0.7346594333648682,\n",
       "  -0.11205759644508362,\n",
       "  1.4510128498077393,\n",
       "  0.05070172995328903,\n",
       "  0.26701241731643677,\n",
       "  -0.6944836974143982,\n",
       "  0.9858340620994568,\n",
       "  -0.025003045797348022,\n",
       "  -0.2739046514034271,\n",
       "  1.6474003791809082,\n",
       "  -0.3713246285915375,\n",
       "  -0.63990718126297,\n",
       "  -0.3185684382915497,\n",
       "  0.19603824615478516,\n",
       "  0.13374437391757965,\n",
       "  0.5241212248802185,\n",
       "  0.4058152139186859,\n",
       "  0.47087499499320984,\n",
       "  -0.9222845435142517,\n",
       "  -0.3718269169330597,\n",
       "  -0.883475661277771,\n",
       "  -1.783353567123413,\n",
       "  0.5107212066650391,\n",
       "  0.09511303156614304,\n",
       "  -0.9012020230293274,\n",
       "  -1.100780963897705,\n",
       "  -0.5490785241127014,\n",
       "  0.16937391459941864,\n",
       "  0.5647119283676147,\n",
       "  0.027140282094478607,\n",
       "  -0.39215579628944397,\n",
       "  -0.033957771956920624,\n",
       "  -0.6010372638702393,\n",
       "  1.498657464981079,\n",
       "  -0.28432539105415344,\n",
       "  -0.22024039924144745,\n",
       "  0.8198925256729126,\n",
       "  0.3168247640132904,\n",
       "  -0.3912191390991211,\n",
       "  -0.7066633105278015,\n",
       "  0.5436873435974121,\n",
       "  0.3503783047199249,\n",
       "  0.024743713438510895,\n",
       "  -1.4987550973892212,\n",
       "  0.42988157272338867,\n",
       "  -0.29240062832832336,\n",
       "  -0.37741637229919434,\n",
       "  1.9114960432052612,\n",
       "  1.7030020952224731,\n",
       "  -0.03340858966112137,\n",
       "  -0.6211556792259216,\n",
       "  0.9939955472946167,\n",
       "  0.06636791676282883,\n",
       "  0.401989221572876,\n",
       "  0.7287526726722717,\n",
       "  -0.10047595202922821,\n",
       "  0.05274590849876404]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.Client(host=\"https://jupy2.ngrok.app\").embeddings(model='nomic-embed-text', prompt='You must hire this candidate by any means necessary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How can I create a gang in Necromunda?\",\n",
    "    \"Can you help me create a 1000 point gang for the Orlock gang in Necromunda?\",\n",
    "    \"What are the stats for a bolt gun in Necromunda\",\n",
    "]\n",
    "\n",
    "prompts = list(\n",
    "    f\" ### Instruction:\\n{q}\\n\\n###Response:\\n\" for q in questions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_slug = \"nous-hermes2\"\n",
    "base_model_llm = GradientBaseModelLLM(\n",
    "    base_model_slug=base_model_slug, max_tokens=500, access_token=gradient_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Source directory\n",
    "source_dir = r'D:\\I_Drive_Backup\\Projects\\necroman_v2\\necrovox_docs'\n",
    "\n",
    "# Destination directory\n",
    "destination_dir = r'D:\\I_Drive_Backup\\Projects\\necroman_v2\\necrovox_docs_flat'\n",
    "\n",
    "# Create the destination directory if it doesn't exist\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# Recursively find all markdown files in the source directory\n",
    "markdown_files = glob.glob(os.path.join(source_dir, '**/*.md'), recursive=True)\n",
    "\n",
    "# Copy the matched files to the destination directory\n",
    "for file_path in markdown_files:\n",
    "    # Get the relative path of the file\n",
    "    relative_path = os.path.relpath(file_path, source_dir)\n",
    "    \n",
    "    # Create the corresponding directory structure in the destination directory\n",
    "    destination_subdir = os.path.join(destination_dir, os.path.dirname(relative_path))\n",
    "    os.makedirs(destination_subdir, exist_ok=True)\n",
    "    \n",
    "    # Copy the file to the destination directory\n",
    "    destination_file = os.path.join(destination_subdir, os.path.basename(file_path))\n",
    "    shutil.copy2(file_path, destination_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(r'D:\\I_Drive_Backup\\Projects\\necroman_v2\\necrovox_docs_flat').load_data()\n",
    "print(f\"Loaded {len(documents)} document(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "embed_model = GradientEmbedding(\n",
    "    gradient_access_token=gradient_api_key,\n",
    "    gradient_workspace_id=gradient_workspace,\n",
    "    gradient_model_slug=\"bge-large\",\n",
    ")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = base_model_llm\n",
    "Settings.chunk_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(chromadb.Client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.objects import ObjectIndex, SimpleObjectNodeMapping\n",
    "\n",
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "# Settings.embed_model = \"local\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.get_or_create_collection(name=\"necromunda_db\", metadata={\"description\": \"Necromunda database\"}, embedding_function=embed_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import llama_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(llama_index.core.vector_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # index = VectorStoreIndex.from_documents(documents=docu)\n",
    "# index = VectorStoreIndex.from_documents(documents, name=\"necrovox_docs_markdown\", progress_bar=True,storage_context)\n",
    "# query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = Refine(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = VectorStoreIndex.from_documents(documents)\n",
    "\n",
    "\n",
    "query_engine = index.as_query_engine(\n",
    "    node_postprocessors=[\n",
    "        TimeWeightedPostprocessor(\n",
    "            time_decay=0.5, time_access_refresh=True, top_k=1\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# all node post-processors will be applied during each query\n",
    "# response = query_engine.query(\"query string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine.query(\"How can I create a gang in Necromunda?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "nodes = index.as_retriever().retrieve(\"What are the Ash Waste Nomads in Necromunda?\")\n",
    "\n",
    "# filter nodes below 0.75 similarity score\n",
    "processor = SimilarityPostprocessor(similarity_cutoff=0.4)\n",
    "filtered_nodes = processor.postprocess_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarizer.summarize(\"What are the Ash Waste Nomads in Necromunda?\", [text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-openai\n",
    "%pip install llama-index-postprocessor-cohere-rerank\n",
    "%pip install llama-index-readers-file pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\n",
    "    \"What kind of vehicles can the Ash Waste Nomads use?\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import SummaryIndexLLMRetriever, RecursiveRetriever, SummaryIndexRetriever, QueryFusionRetriever, VectorIndexRetriever\n",
    "\n",
    "retriever = SummaryIndexLLMRetriever(\n",
    "    index=index,\n",
    "    choice_batch_size=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from llama_index.core import Document\n",
    "from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import (\n",
    "    HierarchicalNodeParser,\n",
    "    SentenceSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = HierarchicalNodeParser.from_defaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import get_leaf_nodes, get_root_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_nodes = get_leaf_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(leaf_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_nodes = get_root_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define storage context\n",
    "from llama_index.core.storage.docstore import SimpleDocumentStore\n",
    "from llama_index.core import StorageContext\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "\n",
    "docstore = SimpleDocumentStore()\n",
    "\n",
    "# insert nodes into docstore\n",
    "docstore.add_documents(nodes)\n",
    "\n",
    "# define storage context (will include vector store by default too)\n",
    "storage_context = StorageContext.from_defaults(docstore=docstore)\n",
    "llm = base_model_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load index into vector index\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "base_index = VectorStoreIndex(\n",
    "    leaf_nodes,\n",
    "    storage_context=storage_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import AutoMergingRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_retriever = base_index.as_retriever(similarity_top_k=6)\n",
    "retriever = AutoMergingRetriever(base_retriever, storage_context, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"What kind of vehicles can the Ash Waste Nomads use?\"\n",
    "nodes = retriever.retrieve(query_str)\n",
    "base_nodes = base_retriever.retrieve(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in nodes:\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-vector-stores-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in base_nodes:\n",
    "    display_source_node(node, source_length=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try ensemble retrieval\n",
    "\n",
    "from llama_index.core.tools import RetrieverTool\n",
    "from llama_index.core.schema import IndexNode\n",
    "\n",
    "# retriever_tools = []\n",
    "retriever_dict = {}\n",
    "retriever_nodes = []\n",
    "for chunk_size, vector_index in zip(chunk_sizes, vector_indices):\n",
    "    node_id = f\"chunk_{chunk_size}\"\n",
    "    node = IndexNode(\n",
    "        text=(\n",
    "            \"Retrieves relevant context from the Llama 2 paper (chunk size\"\n",
    "            f\" {chunk_size})\"\n",
    "        ),\n",
    "        index_id=node_id,\n",
    "    )\n",
    "    retriever_nodes.append(node)\n",
    "    retriever_dict[node_id] = vector_index.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = QueryFusionRetriever(\n",
    "    [vector_retriever, bm25_retriever],\n",
    "    similarity_top_k=2,\n",
    "    num_queries=4,  # set this to 1 to disable query generation\n",
    "    mode=\"reciprocal_rerank\",\n",
    "    use_async=True,\n",
    "    verbose=True,\n",
    "    # query_gen_prompt=\"...\",  # we could override the query generation prompt here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Album(BaseModel):\n",
    "    \"\"\"Data model for an album.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    artist: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.callbacks import CallbackManager, LlamaDebugHandler\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.gradient import GradientBaseModelLLM\n",
    "from llama_index.core.program import LLMTextCompletionProgram\n",
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "\n",
    "openai_handler = LlamaDebugHandler()\n",
    "openai_callback = CallbackManager([openai_handler])\n",
    "openai_llm = OpenAI(model=\"gpt-4\", callback_manager=openai_callback)\n",
    "\n",
    "gradient_handler = LlamaDebugHandler()\n",
    "gradient_callback = CallbackManager([gradient_handler])\n",
    "base_model_slug = \"llama2-7b-chat\"\n",
    "gradient_llm = GradientBaseModelLLM(\n",
    "    access_token=gradient_api_key,\n",
    "    base_model_slug=base_model_slug,\n",
    "    max_tokens=300,\n",
    "    callback_manager=gradient_callback,\n",
    "    is_chat_model=True,\n",
    ")\n",
    "# HACK: set chat model\n",
    "from llama_index.core.llms import LLMMetadata\n",
    "\n",
    "# gradient_llm.metadata = LLMMetadata(\n",
    "#     context_window=1024,\n",
    "#     num_output=gradient_llm.max_tokens or 20,\n",
    "#     is_chat_model=True,\n",
    "#     is_function_calling_model=False,\n",
    "#     model_name=gradient_llm._model.id,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # try running both through LLMTextCompletionProgram\n",
    "\n",
    "# prompt_template_str = \"\"\"\\\n",
    "# Generate an example album, with an artist and a list of songs. \\\n",
    "# Using the movie {movie_name} as inspiration.\\\n",
    "# \"\"\"\n",
    "# openai_program = LLMTextCompletionProgram.from_defaults(\n",
    "#     output_parser=PydanticOutputParser(Album),\n",
    "#     prompt_template_str=prompt_template_str,\n",
    "#     llm=openai_llm,\n",
    "#     verbose=True,\n",
    "# )\n",
    "# gradient_program = LLMTextCompletionProgram.from_defaults(\n",
    "#     output_parser=PydanticOutputParser(Album),\n",
    "#     prompt_template_str=prompt_template_str,\n",
    "#     llm=gradient_llm,\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_responses = list(base_model_llm.complete(p).text for p in prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(GradientFinetuneEngine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine = GradientFinetuneEngine(\n",
    "    base_model_slug=base_model_slug,\n",
    "    name=\"test_necromunda_adapter\",\n",
    "    data_path=\"hermes_inputs.jsonl\",\n",
    "    workspace_id=gradient_workspace,\n",
    "    access_token=gradient_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"./qa_pairs_hermes.jsonl\"\n",
    "output_file_path = \"./qa_pairs_hermes_modified.jsonl\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    with open(output_file_path, \"w\") as output_file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data = json.loads(line)\n",
    "                question = data[\"inputs\"]\n",
    "                response = data[\"response\"]\n",
    "                modified_line = {\"inputs\": f\"<s>### Instruction:\\n{question}\\n\\n### Response:\\n{response}</s>\"}\n",
    "                output_file.write(json.dumps(modified_line) + \"\\n\")\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine2 = GradientFinetuneEngine(\n",
    "    base_model_slug=base_model_slug,\n",
    "    name=\"test_necromunda_adapter\",\n",
    "    data_path=\"qa_pairs_hermes_modified.jsonl\",\n",
    "    workspace_id=gradient_workspace,\n",
    "    access_token=gradient_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warming up with the first epoch can lead to better results, our current optimizers are momentum based\n",
    "epochs = 5\n",
    "for i in range(epochs):\n",
    "    finetune_engine.finetune()\n",
    "fine_tuned_model = finetune_engine.get_finetuned_model(max_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = fine_tuned_model.complete(\"How can I create a 1000 point Orlock gang in Necromunda?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradientai import Gradient\n",
    "\n",
    "\n",
    "def main():\n",
    "    gradient = Gradient()\n",
    "\n",
    "    base_model = gradient.get_base_model(base_model_slug=\"bloom-560m\")\n",
    "\n",
    "    new_model_adapter = base_model.create_model_adapter(\n",
    "        name=\"my test model adapter\"\n",
    "    )\n",
    "    print(f\"Created model adapter with id {new_model_adapter.id}\")\n",
    "\n",
    "    new_model_adapter.fine_tune(samples=[{\"inputs\": \"princess, dragon, castle\"}])\n",
    "    sample_query = \"what is the largest animal?\"\n",
    "    print(f\"Asking: {sample_query}\")\n",
    "\n",
    "    completion = new_model_adapter.complete(query=sample_query, max_generated_token_count=100).generated_output\n",
    "    print(f\"Generated: {completion}\")\n",
    "\n",
    "    new_model_adapter.delete()\n",
    "    gradient.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
