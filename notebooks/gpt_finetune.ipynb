{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning With LlamaIndex and GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports And Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.10.26)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.2.2)\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.1.11)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.26 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.10.26)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.1.7)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.9.48)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.1.14)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.1.5)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.1.3)\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.1.13)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index) (0.1.4)\n",
      "Requirement already satisfied: openai>=1.14.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.16.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.6.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2023.12.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.26.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.1.16)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.5.8)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.26.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.1.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.26->llama-index) (1.14.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
      "Requirement already satisfied: pydantic>=1.10 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.15->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.10.15)\n",
      "Requirement already satisfied: anyio in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.26->llama-index) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.1.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.26->llama-index) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.26->llama-index) (3.20.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (2023.4)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.26->llama-index) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.26->llama-index) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-llms-gradient in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: gradientai<2.0.0,>=1.6.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-gradient) (1.8.1)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-gradient) (0.10.26)\n",
      "Requirement already satisfied: aenum>=3.1.11 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient) (3.1.11)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.10.5 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient) (1.10.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient) (2.1.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (0.6.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (2023.12.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (0.26.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (0.1.16)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.5.8)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.26.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.16.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (2.1.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.14.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.3.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (0.14.0)\n",
      "Requirement already satisfied: click in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (3.20.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (2023.4)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-gradient) (23.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-finetuning in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.4)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-finetuning) (0.10.26)\n",
      "Requirement already satisfied: llama-index-embeddings-adapter<0.2.0,>=0.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-finetuning) (0.1.3)\n",
      "Requirement already satisfied: llama-index-llms-gradient<0.2.0,>=0.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-finetuning) (0.1.2)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-finetuning) (0.1.14)\n",
      "Requirement already satisfied: llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-finetuning) (0.1.4)\n",
      "Requirement already satisfied: sentence-transformers<3.0.0,>=2.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-finetuning) (2.6.1)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.9.1)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.6.3)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2023.12.2)\n",
      "Requirement already satisfied: httpx in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.26.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.15 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.1.16)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.5.8)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.8.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.26.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.16.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.1.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.9.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.9.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.14.1)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (2.1.2)\n",
      "Requirement already satisfied: gradientai<2.0.0,>=1.6.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (1.8.1)\n",
      "Requirement already satisfied: cohere<6.0.0,>=5.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (5.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (4.36.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (0.20.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.1)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.9.4)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (1.10.15)\n",
      "Requirement already satisfied: tokenizers<0.16.0,>=0.15.2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (0.15.2)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.20240311 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cohere<6.0.0,>=5.1.1->llama-index-postprocessor-cohere-rerank<0.2.0,>=0.1.1->llama-index-finetuning) (2.31.0.20240403)\n",
      "Requirement already satisfied: aenum>=3.1.11 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (3.1.11)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.25.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (2.1.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (23.2)\n",
      "Requirement already satisfied: click in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.0.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (1.12)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (0.4.6)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (0.4.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (3.20.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2022.6)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-finetuning) (2023.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.3.0->llama-index-finetuning) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dcarm\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->gradientai<2.0.0,>=1.6.0->llama-index-llms-gradient<0.2.0,>=0.1.1->llama-index-finetuning) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\dcarm\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-adapter<0.2.0,>=0.1.2->llama-index-finetuning) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index --upgrade\n",
    "%pip install llama-index-llms-gradient\n",
    "%pip install llama-index-finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import nest_asyncio\n",
    "import openai\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# import\n",
    "from llama_index import (\n",
    "    KnowledgeGraphIndex,\n",
    "    ServiceContext,\n",
    "    SimpleDirectoryReader,\n",
    "    SimpleKeywordTableIndex,\n",
    "    StorageContext,\n",
    "    SummaryIndex,\n",
    "    VectorStoreIndex,\n",
    "    get_response_synthesizer,\n",
    "    load_index_from_storage,\n",
    "    set_global_service_context,\n",
    ")\n",
    "from llama_index.agent import ReActAgent\n",
    "from llama_index.callbacks import CallbackManager\n",
    "from llama_index.composability import ComposableGraph\n",
    "from llama_index.embeddings import (\n",
    "    AdapterEmbeddingModel,\n",
    "    HuggingFaceEmbedding,\n",
    "    OpenAIEmbedding,\n",
    "    resolve_embed_model,\n",
    ")\n",
    "from llama_index.embeddings.adapter_utils import TwoLayerNN\n",
    "from llama_index.evaluation import (\n",
    "    DatasetGenerator,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    "    QueryResponseDataset,\n",
    "    generate_question_context_pairs,\n",
    ")\n",
    "from llama_index.extractors import (\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    ")\n",
    "from llama_index.finetuning import EmbeddingAdapterFinetuneEngine\n",
    "from llama_index.finetuning.cross_encoders.cross_encoder import (\n",
    "    CrossEncoderFinetuneEngine,\n",
    ")\n",
    "from llama_index.finetuning.cross_encoders.dataset_gen import (\n",
    "    generate_ce_fine_tuning_dataset,\n",
    "    generate_synthetic_queries_over_documents,\n",
    ")\n",
    "from llama_index.ingestion import IngestionPipeline\n",
    "from llama_index.llama_dataset import (\n",
    "    CreatedBy,\n",
    "    CreatedByType,\n",
    "    LabelledRagDataExample,\n",
    "    LabelledRagDataset,\n",
    ")\n",
    "from llama_index.llama_dataset.generator import RagDatasetGenerator\n",
    "from llama_index.llama_pack import download_llama_pack\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.node_parser import MarkdownNodeParser, SentenceSplitter\n",
    "from llama_index.postprocessor import SimilarityPostprocessor\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.readers import (\n",
    "    NotionPageReader,\n",
    "    SimpleDirectoryReader,\n",
    ")\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.text_splitter import SentenceSplitter, TokenTextSplitter\n",
    "from llama_index.tools import QueryEngineTool\n",
    "from llama_index.tools.query_engine import QueryEngineTool\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "client = OpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "os.environ[\"COHERE_API_KEY\"] = COHERE_API_KEY\n",
    "integration_token = os.getenv(\"NOTION_API_KEY\")\n",
    "os.environ[\"NOTION_INTEGRATION_TOKEN\"] = os.getenv(\"NOTION_API_KEY\")\n",
    "necromunda_db_id = os.getenv(\"NECROMUNDA_DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Congifuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "# llm = OpenAI(temperature=0, model=\"gpt-4-0613\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)\n",
    "\n",
    "gpt_35_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0.3)\n",
    ")\n",
    "gpt4_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-4-0613\", temperature=0.3)\n",
    ")\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "callback_manager = CallbackManager([])\n",
    "\n",
    "gpt_35_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo-0613\", temperature=0.3),\n",
    "    callback_manager=callback_manager,\n",
    ")\n",
    "gpt_4_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-4-0613\", temperature=0.3),\n",
    "    callback_manager=callback_manager,\n",
    ")\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "reader = SimpleDirectoryReader(\"../necrovox_docs/\")\n",
    "documents = reader.load_data()\n",
    "\n",
    "\n",
    "embed_model = OpenAIEmbedding(embed_batch_size=10)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "\n",
    "# optionally set a global service context\n",
    "set_global_service_context(service_context)\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=OPENAI_API_KEY, model_name=\"text-embedding-ada-002\"\n",
    ")\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from Notion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notion_reader = NotionPageReader(integration_token=integration_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notion_reader.integration_token = integration_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api.notion.com/v1/search\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"query\": \"Necromunda\",\n",
    "  \"sort\": {\n",
    "    \"direction\": \"descending\",\n",
    "    \"timestamp\": \"last_edited_time\"\n",
    "  }\n",
    "})\n",
    "headers = {\n",
    "  'Content-Type': 'application/json',\n",
    "  'Authorization': f'Bearer {integration_token}',\n",
    "  'Cookie': '__cf_bm=_54FCr6wYRyRIFeuVVYGX7RNbPAjRv4BoeQsCp1BnF8-1705702350-1-AZnzjU/14Xpspdgy0vIMtwduuhle3eq1wIEW1yvdkpUGDwwhMxIlKwpLiN55PCVPq4x1zRbZVS7L+3FdCqXqzY0='\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = response.json()['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_ids = [result['id'] for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = notion_reader.load_data(page_ids=page_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = SimpleDirectoryReader(\"../necrovox_docs/\")\n",
    "documents = reader.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Sample Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tokenize with SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = SentenceSplitter().get_nodes_from_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Documents with Markdown Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# If you want to try the MarkdownNodeParser, you can use the following code:\n",
    "md_parser = MarkdownNodeParser()\n",
    "nodes = md_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Vectorstore and Embeddings with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "collection = chroma_client.get_or_create_collection(name=\"necromunda_notion\", embedding_function=openai_ef)\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "embed_model = OpenAIEmbedding(embed_batch_size=10)\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model)\n",
    "# load from disk\n",
    "db = chromadb.PersistentClient(path=\"../necromunda_db/\")\n",
    "# chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=collection)\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necromunda_index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[index.insert(document) for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Query Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using A Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure retriever\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    similarity_top_k=10,\n",
    ")\n",
    "\n",
    "# configure response synthesizer\n",
    "response_synthesizer = get_response_synthesizer()\n",
    "\n",
    "# assemble query engine\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    "    node_postprocessors=[SimilarityPostprocessor(similarity_cutoff=0.7)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query_engine.query(\"What is a Goliath?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Query Engine as Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"necromunda_query_engine\",\n",
    "    description=(\n",
    "        \"Provides information about the Necromunda rules\"\n",
    "    )\n",
    ")\n",
    "query_engine_tools = [query_tool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_parser = SentenceSplitter()\n",
    "# nodes = md_parser.get_nodes_from_documents(documents)\n",
    "extractor = TitleExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# node_parser = SentenceSplitter(chunk_size=512)\n",
    "\n",
    "\n",
    "# use transforms directly\n",
    "# nodes = node_parser(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "transformations = [\n",
    "    TokenTextSplitter(chunk_size=512, chunk_overlap=128),\n",
    "    TitleExtractor(nodes=5),\n",
    "    QuestionsAnsweredExtractor(questions=3),\n",
    "]\n",
    "text_splitter =  TokenTextSplitter(chunk_size=512, chunk_overlap=128)\n",
    "title_extractor = TitleExtractor(nodes=5)\n",
    "qa_extractor = QuestionsAnsweredExtractor(questions=3)\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    transformations=[text_splitter, title_extractor, qa_extractor]\n",
    ")\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.storage_context.persist(\"./necrovox_index\")\n",
    "index.storage_context.persist(\"./necrovox_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"./necrovox_index2\")\n",
    "\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)\n",
    "index.storage_context.persist(persist_dir=\"./necrovox_index2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0].dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 'queries' from train_dataset.json\n",
    "\n",
    "with open(\"./train_dataset.json\", \"r\") as f:\n",
    "    train_dataset = json.load(f)\n",
    "    # queries = [q[\"query\"] for q in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the values of train_dataset['queries'] to a list\n",
    "queries = []\n",
    "for q in train_dataset['queries'].values():\n",
    "    queries.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "qa_prompt_tmpl_str = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def augment_data_with_retrieval(dataset, retriever, separate_context=False):\n",
    "    data_list = dataset.qr_pairs\n",
    "    new_data_list = []\n",
    "    for query_str, response in tqdm(data_list):\n",
    "        retrieved_nodes = retriever.retrieve(query_str)\n",
    "        retrieved_txts = [n.get_content() for n in retrieved_nodes]\n",
    "        if separate_context:\n",
    "            for retrieved_txt in retrieved_txts:\n",
    "                fmt_query_str = qa_prompt_tmpl.format(\n",
    "                    query_str=query_str, context_str=retrieved_txt\n",
    "                )\n",
    "                new_data_list.append((fmt_query_str, response))\n",
    "        else:\n",
    "            context_str = \"\\n\\n\".join(retrieved_txts)\n",
    "            fmt_query_str = qa_prompt_tmpl.format(\n",
    "                query_str=query_str, context_str=context_str\n",
    "            )\n",
    "            new_data_list.append((fmt_query_str, response))\n",
    "    return new_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking RAG Pipelines With A LabelledRagDatatset\n",
    "The LabelledRagDataset is meant to be used for evaluating any given RAG pipeline, for which there could be several configurations (i.e. choosing the LLM, values for the similarity_top_k, chunk_size, and others). Weve likened this abstract to traditional machine learning datastets, where X features are meant to predict a ground-truth label y. In this case, we use the query as well as the retrieved contexts as the features and the answer to the query, called reference_answer as the ground-truth label.\n",
    "\n",
    "And of course, such datasets are comprised of observations or examples. In the case of LabelledRagDataset, these are made up with a set of LabelledRagDataExamples.\n",
    "\n",
    "In this notebook, we will show how one can construct a LabelledRagDataset from scratch. Please note that the alternative to this would be to simply download a community supplied LabelledRagDataset from llama-hub in order to evaluate/benchmark your own RAG pipeline on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "    documents=documents,\n",
    "    service_context=service_context,\n",
    "    num_questions_per_chunk=1,  # set the number of questions per nodes\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = dataset_generator.generate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.save_json(\"./eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset = dataset_generator.generate_dataset_from_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dataset"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "df  = rag_dataset.to_pandas()\n",
    "rag_dataset.save_json(\"rag_dataset2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = retriever.retrieve(\"How do I use a blast template?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    display_source_node(node, source_length=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Context Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_dataset.make_predictions_with_retriever(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset = generate_question_context_pairs(\n",
    "    nodes, llm=llm, num_questions_per_chunk=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dataset.save_json(\"./qa_dataset2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = qa_dataset.queries.values()\n",
    "print(list(queries)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Layer NN Apadpter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_embed_model = resolve_embed_model(\"local:BAAI/bge-small-en\")\n",
    "adapter_model = TwoLayerNN(\n",
    "    384,  # input dimension\n",
    "    1024,  # hidden dimension\n",
    "    384,  # output dimension\n",
    "    bias=True,\n",
    "    add_residual=True,\n",
    ")\n",
    "\n",
    "finetune_engine = EmbeddingAdapterFinetuneEngine(\n",
    "    qa_dataset,\n",
    "    base_embed_model,\n",
    "    model_output_path=\"model5_output_test\",\n",
    "    model_checkpoint_path=\"model5_ck\",\n",
    "    adapter_model=adapter_model,\n",
    "    epochs=25,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_2layer = finetune_engine.get_finetuned_model(\n",
    "    adapter_cls=TwoLayerNN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_2layer.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from checkpoint in the midde\n",
    "embed_model_2layer_adapter = AdapterEmbeddingModel(\n",
    "    base_embed_model,\n",
    "    \"model5_output_test\",\n",
    "    TwoLayerNN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install eval_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model from embed_model_2layer\n",
    "embed_model_2layer.to_json()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model from checkpoint in the midde\n",
    "embed_model_2layer = AdapterEmbeddingModel(\n",
    "    base_embed_model,\n",
    "    \"model5_output_test\",\n",
    "    TwoLayerNN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval_utils import evaluate, display_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_val_results_2layer = evaluate(qa_dataset, embed_model_2layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [optional] save\n",
    "qa_dataset.save_json(\"pg_eval_dataset1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import EmbeddingQAFinetuneDataset\n",
    "\n",
    "with open(\"./pg_eval_dataset1.json\", \"r\") as f:\n",
    "    qa_dataset = EmbeddingQAFinetuneDataset.from_json(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = dict(qa_dataset.dict()['queries'])\n",
    "corpus = dict(qa_dataset.dict()['corpus'])\n",
    "relevant_docs = dict(qa_dataset.dict()['relevant_docs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = str(query_engine.query('How do I use a blast template?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "with open(\"./qa_eval_dataset1.json\", \"w\") as f:\n",
    "    # eval_dataset = json.load(f)\n",
    "    for k,v in queries.items():\n",
    "        print(f\"ID:{k}\\n\\nQuestion: {v}\\n\\n\"\"\")\n",
    "        relevant = relevant_docs[k]\n",
    "        print(f\"Relevant Documents: {relevant}\\n\\n\")\n",
    "        doc = corpus[relevant[0]]\n",
    "\n",
    "        # doc = corpus[relevant[]]\n",
    "        question = f\"Relevant Documentation{doc}\\n\\nQuestion: {v}\\n\\n\"\n",
    "        response = str(query_engine.query(question))\n",
    "        print(f\"Response: {response}\\n\\n\")\n",
    "        out_dict = {\"question\": v, \"response\": response}\n",
    "        results.append(out_dict)\n",
    "        f.writelines(json.dumps(out_dict))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import RelevancyEvaluator, FaithfulnessEvaluator\n",
    "from llama_index import PromptTemplate\n",
    "query_eval_tmpl = PromptTemplate(\n",
    "    \"Your task is to evaluate the following: If the response for the query\"\n",
    "    \" isn't able to answer the question provided.\\nIf query isn't able to\"\n",
    "    \" answer the question, answer NO.\\nOtherwise answer YES.\\nTo elaborate,\"\n",
    "    \" you might get an answer like the following: 'The context does not\"\n",
    "    \" contain the answer to this question.'Please return NO in that case. You\"\n",
    "    \" be given the query and response. Return YES or NO as the answer.\\nQuery:\"\n",
    "    \" \\n {query_str}\\nResponse: \\n {response_str}\\nAnswer: \"\n",
    ")\n",
    "\n",
    "eval_llm = OpenAI(model=\"gpt-4-0613\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(path: str, out_path: str):\n",
    "    with open(path, \"r\") as fp, open(out_path, \"w\") as out_fp:\n",
    "        lines = fp.readlines()\n",
    "        new_lines = []\n",
    "        for idx, line in enumerate(lines):\n",
    "            qa_pair = json.loads(line)\n",
    "            eval = eval_llm.complete(\n",
    "                query_eval_tmpl.format(\n",
    "                    query_str=qa_pair[\"query\"], response_str=qa_pair[\"response\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "            print(f\"[{idx}] QA Pair: {qa_pair} \\n Eval: {eval}\")\n",
    "            if \"NO\" in str(eval):\n",
    "                continue\n",
    "            else:\n",
    "                new_lines.append(line)\n",
    "        out_fp.writelines(new_lines)\n",
    "        return new_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read the file\n",
    "with open(\"./qa_eval_dataset1.json\", \"r\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Correct the formatting using regex\n",
    "data = re.sub(r\"}{\", \"}\\n{\", data)\n",
    "\n",
    "# Write the corrected data back to the file\n",
    "with open(\"./qa_eval_dataset1.json\", \"w\") as f:\n",
    "    f.write(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_data(\"./qa_eval_dataset1.json\", \"./filtered_qa_eval_dataset1.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "\n",
    "def split_train_val(\n",
    "    path: str, out_train_path: str, out_val_path: str, train_split=0.7\n",
    "):\n",
    "    with open(path, \"r\") as fp:\n",
    "        lines = fp.readlines()\n",
    "\n",
    "        # shuffle the lines to make sure that the \"train questions\" cover most fo the context\n",
    "        shuffled_lines = deepcopy(lines)\n",
    "        random.shuffle(shuffled_lines)\n",
    "\n",
    "        split_idx = int(train_split * len(shuffled_lines))\n",
    "        train_lines = shuffled_lines[:split_idx]\n",
    "        val_lines = shuffled_lines[split_idx:]\n",
    "        with open(out_train_path, \"w\") as out_fp:\n",
    "            out_fp.write(\"\".join(train_lines))\n",
    "\n",
    "        with open(out_val_path, \"w\") as out_fp:\n",
    "            out_fp.write(\"\".join(val_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train_val(\n",
    "    \"./filtered_qa_eval_dataset1.jsonl\",\n",
    "    \"./qa_pairs_train1.jsonl\",\n",
    "    \"./qa_pairs_val1.jsonl\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"./qa_pairs_train1.jsonl\", \"r\")\n",
    "out_fp = open(\"./qa_pairs_openai1.jsonl\", \"w\")\n",
    "# TODO: try with different system prompts\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": (\n",
    "        \"You are a helpful assistant helping to answer questions about the\"\n",
    "        \" Necromunda rules.\"\n",
    "    ),\n",
    "}\n",
    "for line in fp:\n",
    "    try:\n",
    "        qa_pair = json.loads(line)\n",
    "        user_prompt = {\"role\": \"user\", \"content\": qa_pair[\"query\"]}\n",
    "        assistant_prompt = {\"role\": \"assistant\", \"content\": qa_pair[\"response\"]}\n",
    "        out_dict = {\n",
    "            \"messages\": [system_prompt, user_prompt, assistant_prompt],\n",
    "        }\n",
    "        out_fp.write(json.dumps(out_dict) + \"\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing line: {line}\")\n",
    "        print(f\"Error message: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.finetuning import OpenAIFinetuneEngine\n",
    "finetune_engine = OpenAIFinetuneEngine(\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"./qa_pairs_openai1.jsonl\",\n",
    "    # start_job_id=\"<start-job-id>\"  # if you have an existing job, can specify id here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_engine.finetune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.fine_tuning.jobs.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = finetune_engine.get_finetuned_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_json = ft_model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import ServiceContext\n",
    "\n",
    "ft_context = ServiceContext.from_defaults(\n",
    "    llm=ft_model,\n",
    "    callback_manager=callback_manager,\n",
    "\n",
    ")\n",
    "# baseline RAG system\n",
    "ft_index = VectorStoreIndex(nodes, service_context=ft_context)\n",
    "ft_query_engine = ft_index.as_query_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_cohere_rerank = True\n",
    "\n",
    "if include_cohere_rerank:\n",
    "    %pip install cohere -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.evaluation import RetrieverEvaluator\n",
    "\n",
    "metrics = [\"mrr\", \"hit_rate\"]\n",
    "\n",
    "if include_cohere_rerank:\n",
    "    metrics.append(\n",
    "        \"cohere_rerank_relevancy\"  # requires COHERE_API_KEY environment variable to be set\n",
    "    )\n",
    "\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id, sample_query = list(qa_dataset.queries.items())[20]\n",
    "sample_expected = qa_dataset.relevant_docs[sample_id]\n",
    "\n",
    "eval_result = retriever_evaluator.evaluate(sample_query, sample_expected)\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it out on an entire dataset\n",
    "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(name, eval_results):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "\n",
    "    metric_dicts = []\n",
    "    for eval_result in eval_results:\n",
    "        metric_dict = eval_result.metric_vals_dict\n",
    "        metric_dicts.append(metric_dict)\n",
    "\n",
    "    full_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "    hit_rate = full_df[\"hit_rate\"].mean()\n",
    "    mrr = full_df[\"mrr\"].mean()\n",
    "    columns = {\"retrievers\": [name], \"hit_rate\": [hit_rate], \"mrr\": [mrr]}\n",
    "\n",
    "    if include_cohere_rerank:\n",
    "        crr_relevancy = full_df[\"cohere_rerank_relevancy\"].mean()\n",
    "        columns.update({\"cohere_rerank_relevancy\": [crr_relevancy]})\n",
    "\n",
    "    metric_df = pd.DataFrame(columns)\n",
    "\n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(\"top-2 eval\", eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "RagEvaluatorPack = download_llama_pack(\"RagEvaluatorPack\", \"./pack\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_evaluator = RagEvaluatorPack(\n",
    "    query_engine=query_engine,  # built with the same source Documents as the rag_dataset\n",
    "    rag_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = QueryResponseDataset.from_json(\"./eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_datadet = generate_ce_fine_tuning_dataset(documents=documents, questions_list=queries[:500], max_chunk_length=1000, llm=llm, qa_doc_relevance_prompt=qa_prompt_tmpl, top_k=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_finetuning_data_list = []\n",
    "for doc in documents:\n",
    "    questions_list = doc[\"questions\"]\n",
    "    documents = [Document(text=doc['text'])]\n",
    "    local_finetuning_dataset = generate_ce_fine_tuning_dataset(\n",
    "        documents=documents,\n",
    "        questions_list=questions_list,\n",
    "        max_chunk_length=256,\n",
    "        top_k=5,\n",
    "    )\n",
    "    final_finetuning_data_list.extend(local_finetuning_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context with GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-4\", temperature=0), callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context With GPT-3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0), callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_generator = DatasetGenerator(\n",
    "    nodes[:39],\n",
    "    service_context=eval_context,\n",
    "    show_progress=True,\n",
    "    num_questions_per_chunk=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
